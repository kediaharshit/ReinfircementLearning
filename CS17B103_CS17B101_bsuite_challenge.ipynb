{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS17B103_CS17B101_bsuite-challenge.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('torch': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8-final"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "288e54f50bdc46cfb197ae5cd249df30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a8c036a335214549bdf71fa24aa089d4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c2a6edac58a240d78bf79ad051aab668",
              "IPY_MODEL_93ccefe8a10c44e2a4fd04dd7e62757c",
              "IPY_MODEL_18b62fef395d4acfa8943ab14335a3ef"
            ]
          }
        },
        "a8c036a335214549bdf71fa24aa089d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2a6edac58a240d78bf79ad051aab668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42200ccfe3cb44f8afd295a76a1ddaa7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e6a10099b6545969db83b67b5949f69"
          }
        },
        "93ccefe8a10c44e2a4fd04dd7e62757c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e66d09719f7145c1b7e24ace22337db1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52170d3e27c549bca00a2691d9393d12"
          }
        },
        "18b62fef395d4acfa8943ab14335a3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5219adff68045439e547de906f14e8e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [00:26&lt;00:00, 44.76it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f72fdcecaa9940f7b4730ab3eb6c8762"
          }
        },
        "42200ccfe3cb44f8afd295a76a1ddaa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e6a10099b6545969db83b67b5949f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e66d09719f7145c1b7e24ace22337db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52170d3e27c549bca00a2691d9393d12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5219adff68045439e547de906f14e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f72fdcecaa9940f7b4730ab3eb6c8762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb43897e20584d6a9d033c3b1cdef501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e615bbf425a4021a800758f7245c097",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dbeff19a5ab84363afff6a6dfcdffb7e",
              "IPY_MODEL_e9af7a567af046d8bdac3fbbc1130ca6",
              "IPY_MODEL_ba7ae004ef1d41f698eccce6a58847d8"
            ]
          }
        },
        "8e615bbf425a4021a800758f7245c097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbeff19a5ab84363afff6a6dfcdffb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25c94db0b356475cabfe49468ae4aa82",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63b547ffe8404d5e9c96684194022269"
          }
        },
        "e9af7a567af046d8bdac3fbbc1130ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c40c33c13d8c47d3be0aff3e1561a2ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_294ddce7b6bd4baaa13249d16e8e3417"
          }
        },
        "ba7ae004ef1d41f698eccce6a58847d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_53694f710c2f44c99f4e1b75c3b940e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [00:06&lt;00:00, 24.68it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7e5f4856801480cbe6f07556418b6aa"
          }
        },
        "25c94db0b356475cabfe49468ae4aa82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63b547ffe8404d5e9c96684194022269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c40c33c13d8c47d3be0aff3e1561a2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "294ddce7b6bd4baaa13249d16e8e3417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53694f710c2f44c99f4e1b75c3b940e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7e5f4856801480cbe6f07556418b6aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5a039ff169841ec98809ea6139a1ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_176918e6913048a5b5094704342af225",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ea9252df967459ca1cd70bf5a3b1919",
              "IPY_MODEL_4971d15038bd4d7a97ddb2bc3305dfa1",
              "IPY_MODEL_714fba70c9ac4910b34b0fb7b18554dd"
            ]
          }
        },
        "176918e6913048a5b5094704342af225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ea9252df967459ca1cd70bf5a3b1919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_417f2db6f0b84f5c8d1ea7140b3b34d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5eab53c120234f4fb210e54d66db12f1"
          }
        },
        "4971d15038bd4d7a97ddb2bc3305dfa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db9f689cbae04a7a9ef4258c22f6d594",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 10000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2fc675cd97454bc18d4065fc50ea63f3"
          }
        },
        "714fba70c9ac4910b34b0fb7b18554dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1cf568dd4480407299ec8eb8f8442d83",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/10000 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe715cda8296412a82f10f2d096ae7a7"
          }
        },
        "417f2db6f0b84f5c8d1ea7140b3b34d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5eab53c120234f4fb210e54d66db12f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db9f689cbae04a7a9ef4258c22f6d594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2fc675cd97454bc18d4065fc50ea63f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cf568dd4480407299ec8eb8f8442d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe715cda8296412a82f10f2d096ae7a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b90643be64ef463780000c110329138b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae9c1f6638954eca9b0d6d57c4599622",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_05a4513d50414f78ab5d7590e69786e4",
              "IPY_MODEL_f6660de9ad1942c3a88ef1a0afa18f37",
              "IPY_MODEL_5b5020da4fdd4c4882342541c9481ed3"
            ]
          }
        },
        "ae9c1f6638954eca9b0d6d57c4599622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05a4513d50414f78ab5d7590e69786e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f7ab746656640c993410e97b55d1399",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f75445d8eb204152b19cf14961470c8e"
          }
        },
        "f6660de9ad1942c3a88ef1a0afa18f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b8d5e6b2dc5345d6bcf7e3f6d9003d37",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cbeb94c64f04b4ea049dd77156c0d03"
          }
        },
        "5b5020da4fdd4c4882342541c9481ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70b9a6746dd84eac9ebd24da2c6315a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [00:07&lt;00:00, 140.08it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44c7a32f217c440598578dde68d6ac69"
          }
        },
        "6f7ab746656640c993410e97b55d1399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f75445d8eb204152b19cf14961470c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8d5e6b2dc5345d6bcf7e3f6d9003d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cbeb94c64f04b4ea049dd77156c0d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70b9a6746dd84eac9ebd24da2c6315a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44c7a32f217c440598578dde68d6ac69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef650adaf9164a2cb58e3576b2042544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a2f24b55b584182a1c2dedb710c7c47",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1e7bdc3401ff405db7b0b246917a36bb",
              "IPY_MODEL_69968349a1154b6a8044acea5ae35924",
              "IPY_MODEL_570a444030ad4e4e874d929ae9d05fbd"
            ]
          }
        },
        "1a2f24b55b584182a1c2dedb710c7c47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e7bdc3401ff405db7b0b246917a36bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fcadc60ba4fb4bb58e07bd1aa121a680",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_198644106e7c4108a12f0231ebb46e1e"
          }
        },
        "69968349a1154b6a8044acea5ae35924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_50cc7a2759444da8ae2aefc7bd97827a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba281706fd7c4629b86d985edcc13905"
          }
        },
        "570a444030ad4e4e874d929ae9d05fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2912e854ac2447f0b4625c35b9321bc6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [01:06&lt;00:00, 21.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da84fa0b6c194b18a6e76a7d09bb8d5f"
          }
        },
        "fcadc60ba4fb4bb58e07bd1aa121a680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "198644106e7c4108a12f0231ebb46e1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50cc7a2759444da8ae2aefc7bd97827a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba281706fd7c4629b86d985edcc13905": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2912e854ac2447f0b4625c35b9321bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da84fa0b6c194b18a6e76a7d09bb8d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b661be8c268d4f2ca1b01cfe9d311f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_25b31b5230bc444aaabbff33695372b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_28ae0cb36990470ea877e2e578585def",
              "IPY_MODEL_f1281fd62a4c4b0590d80d95754494f0",
              "IPY_MODEL_c677d66a87b446178a754e14fca068cb"
            ]
          }
        },
        "25b31b5230bc444aaabbff33695372b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28ae0cb36990470ea877e2e578585def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_77ef7dcf0bd4404b851e6fe956f5f5a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  5%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10bfe22c409549798ec7e77c654a8779"
          }
        },
        "f1281fd62a4c4b0590d80d95754494f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_68789599a4ce41539b16a947b413a7a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 52,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ded7492f9a4481ea2fe218e425ad151"
          }
        },
        "c677d66a87b446178a754e14fca068cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d3f219fe33644a396e63cf7c0b5d7ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 52/1000 [00:06&lt;01:53,  8.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d28f8742420e419f8c6fa5549eae877a"
          }
        },
        "77ef7dcf0bd4404b851e6fe956f5f5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10bfe22c409549798ec7e77c654a8779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68789599a4ce41539b16a947b413a7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ded7492f9a4481ea2fe218e425ad151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d3f219fe33644a396e63cf7c0b5d7ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d28f8742420e419f8c6fa5549eae877a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGU0-M8B5I7c"
      },
      "source": [
        "# IITM RL FINAL PROJECT\n",
        "\n",
        "## Problem - bsuite \n",
        "\n",
        "This notebook uses an open source reinforcement learning benchmark known as bsuite. https://github.com/deepmind/bsuite\n",
        "\n",
        "bsuite is a collection of carefully-designed experiments that investigate core capabilities of a reinforcement learning agent.\n",
        "\n",
        "Your task is to use any reinforcement learning techniques at your disposal to get high scores on the environments specified.\n",
        "\n",
        "**Note**: Since the course is on Reinforcement Learning,  please limit yourself to using traditional Reinforcement Learning algorithms, \n",
        "\n",
        "**Do not use deep reinforcement learning.**\n",
        "\n",
        "# How to use this notebook? 📝\n",
        "\n",
        "- This is a shared template and any edits you make here will not be saved. **You\n",
        "should make a copy in your own drive**. Click the \"File\" menu (top-left), then \"Save a Copy in Drive\". You will be working in your copy however you like.\n",
        "\n",
        "<p style=\"text-align: center\"><img src=\"https://gitlab.aicrowd.com/aicrowd/assets/-/raw/master/notebook/aicrowd_notebook_submission_flow.png?inline=false\" alt=\"notebook overview\" style=\"width: 650px;\"/></p>\n",
        "\n",
        "- **Update the config parameters**. You can define the common variables here\n",
        "\n",
        "Variable | Description\n",
        "--- | ---\n",
        "`AICROWD_RESULTS_DIR` | Path to write the output to.\n",
        "`AICROWD_ASSETS_DIR` | In case your notebook needs additional files (like model weights, etc.,), you can add them to a directory and specify the path to the directory here (please specify relative path). The contents of this directory will be sent to AIcrowd for evaluation.\n",
        "`AICROWD_API_KEY` | In order to submit your code to AIcrowd, you need to provide your account's API key. This key is available at https://www.aicrowd.com/participants/me\n",
        "\n",
        "- **Installing packages**. Please use the [Install packages 🗃](#install-packages-) section to install the packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Byw-jeFUlrF",
        "outputId": "e1805981-9497-498c-e5e5-644568078ade"
      },
      "source": [
        "!pip install -q aicrowd-cli"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██████▍                         | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 20kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 30kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 40kB 10.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 5.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 32.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 38.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 8.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 4.9MB/s \n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j2VFISn5I7j"
      },
      "source": [
        "# AIcrowd Runtime Configuration 🧷\n",
        "\n",
        "Get login API key from https://www.aicrowd.com/participants/me\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD-ipReq5I7j"
      },
      "source": [
        "import os\n",
        "\n",
        "AICROWD_RESULTS_DIR = os.getenv(\"OUTPUTS_DIR\", \"results\")\n",
        "os.environ[\"RESULTS_DIR\"] = AICROWD_RESULTS_DIR\n",
        "API_KEY = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZj1bg7kUqL0",
        "outputId": "2d2b58cb-1428-42bb-fb29-43159bde0de5"
      },
      "source": [
        "!aicrowd login --api-key $API_KEY"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mSaved API Key successfully!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaPR_bc65I7g"
      },
      "source": [
        "# Install packages 🗃\n",
        "\n",
        "Please add all pacakage installations in this section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yq9gIrK5I7h",
        "outputId": "9651d626-15d0-4bd9-8fb3-4690a12652d3"
      },
      "source": [
        "!pip install git+http://gitlab.aicrowd.com/nimishsantosh107/bsuite.git\n",
        "!pip install tabulate\n",
        "!pip install tqdm\n",
        "\n",
        "## Add any other installations you need here"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+http://gitlab.aicrowd.com/nimishsantosh107/bsuite.git\n",
            "  Cloning http://gitlab.aicrowd.com/nimishsantosh107/bsuite.git to /tmp/pip-req-build-dizt4gxs\n",
            "  Running command git clone -q http://gitlab.aicrowd.com/nimishsantosh107/bsuite.git /tmp/pip-req-build-dizt4gxs\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from bsuite==0.3.5) (0.12.0)\n",
            "Collecting dm_env\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/84/c96b6544b8a2cfefc663b7dbd7fc0c2f2c3b6cbf68b0171775693bda2a66/dm_env-1.4-py3-none-any.whl\n",
            "Collecting frozendict\n",
            "  Downloading https://files.pythonhosted.org/packages/6d/29/edb363cf898269cb322d0186baa0bd02874a69691d9dec8728b644fbcedc/frozendict-2.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from bsuite==0.3.5) (0.17.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bsuite==0.3.5) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bsuite==0.3.5) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from bsuite==0.3.5) (1.1.5)\n",
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.7/dist-packages (from bsuite==0.3.5) (0.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bsuite==0.3.5) (1.4.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from bsuite==0.3.5) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bsuite==0.3.5) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from bsuite==0.3.5) (1.1.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm_env->bsuite==0.3.5) (0.1.6)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->bsuite==0.3.5) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->bsuite==0.3.5) (1.5.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bsuite==0.3.5) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bsuite==0.3.5) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bsuite==0.3.5) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bsuite==0.3.5) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->bsuite==0.3.5) (2018.9)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->bsuite==0.3.5) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from plotnine->bsuite==0.3.5) (0.5.1)\n",
            "Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->bsuite==0.3.5) (1.1.0)\n",
            "Requirement already satisfied: mizani>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from plotnine->bsuite==0.3.5) (0.6.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->bsuite==0.3.5) (2.5.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->bsuite==0.3.5) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->bsuite==0.3.5) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->bsuite==0.3.5) (2.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->bsuite==0.3.5) (0.16.0)\n",
            "Requirement already satisfied: palettable in /usr/local/lib/python3.7/dist-packages (from mizani>=0.6.0->plotnine->bsuite==0.3.5) (3.3.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->bsuite==0.3.5) (4.4.2)\n",
            "Building wheels for collected packages: bsuite\n",
            "  Building wheel for bsuite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bsuite: filename=bsuite-0.3.5-cp37-none-any.whl size=252042 sha256=93594083833d9fa824022c3516535deedc89cbefc614bb6cb44ea17de618733f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2gdmrrf6/wheels/61/ea/06/77c82c07765fb8608e50e6c66bc566fa6d113c725bc6937e7b\n",
            "Successfully built bsuite\n",
            "Installing collected packages: dm-env, frozendict, bsuite\n",
            "Successfully installed bsuite-0.3.5 dm-env-1.4 frozendict-2.0.2\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (0.8.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.61.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHwAh4zAUxxJ"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXe8ZvdcQ8mr"
      },
      "source": [
        "import gym\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotnine as gg\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import bsuite\n",
        "from bsuite.aicrowd import environments\n",
        "from bsuite.aicrowd.runner import Runner\n",
        "from bsuite.aicrowd.analysis import Analyzer\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "gg.theme_set(gg.theme_bw(base_size=16, base_family='serif'))\n",
        "gg.theme_update(figure_size=(3, 1), panel_spacing_x=0.5, panel_spacing_y=0.5)\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBrvjPvuA_-t"
      },
      "source": [
        "# **Agent Class**\n",
        "\n",
        "You can modify the AGENT TEMPLATE below and implement the logic of your agent. Your agent must implement a few methods that will be called by the `Runner` class.\n",
        "* `__init__` - put any initialization code here.\n",
        "* `get_action` - takes in a `state` and returns an `action`.\n",
        "* `learn` - takes in `(state, action, reward, next_state)`, implements the learning logic.\n",
        "* `get_state` - takes in a raw `observation` directly from the env, discretizes it and returns a `state`.\n",
        "\n",
        "In addition to these, you may implement other methods which can be called by the above methods.\n",
        "\n",
        "Since there are multiple environments, you may need unique hyper parameters for each environment. Instantiate the agent while passing in the hyper parameters in a dictionary using the `agent_config` parameter so that each environment can use different hyper parameters for the agent while using a single `Agent` class for all of them.  You can use any names for the keys in the config dictionary.   \n",
        "\n",
        "An example `RandomAgent` is given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKO-baWEBBhf"
      },
      "source": [
        "# *** YOU CAN EDIT THIS CELL ***\n",
        "# AGENT TEMPLATE\n",
        "class Agent:\n",
        "    def __init__(self, agent_config=None):\n",
        "        self.config = agent_config\n",
        "        pass\n",
        "\n",
        "    def get_action(self, state):\n",
        "        '''\n",
        "        PARAMETERS  : \n",
        "            - state - discretized 'state'\n",
        "        RETURNS     : \n",
        "            - action - 'action' to be taken\n",
        "        '''\n",
        "        raise NotImplementedError\n",
        "        return action\n",
        "    \n",
        "    def learn(self, state, action, reward, next_state, done):\n",
        "        '''\n",
        "        PARAMETERS  : \n",
        "            - state - discretized 'state'\n",
        "            - action - 'action' performed in 'state'\n",
        "            - reward - 'reward' received due to action taken\n",
        "            - next_state - discretized 'next_state'\n",
        "            - done - status flag to represent if an episode is done or not\n",
        "        RETURNS     : \n",
        "            - NIL\n",
        "        '''\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_state(self, observation):\n",
        "        '''\n",
        "        PARAMETERS  : \n",
        "            - observation - raw 'observation' from environment\n",
        "        RETURNS     : \n",
        "            - state - discretized 'state' from raw 'observation'\n",
        "        '''\n",
        "        raise NotImplementedError\n",
        "        return state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSVqoF2eYlc0"
      },
      "source": [
        "# *** YOU CAN EDIT THIS CELL ***\n",
        "# DO NOT rename the config dictionaries as the evaluator references them. However, you may use any names for the keys in them.\n",
        "catch_config = {\"env_name\": \"catch\"}\n",
        "catch_noise_config = {\"env_name\": \"catch_noise\"}\n",
        "cartpole_config = {\"env_name\": \"cartpole\"}\n",
        "cartpole_noise_config = {\"env_name\": \"cartpole_noise\"}\n",
        "mountaincar_config = {\"env_name\": \"mountaincar\"}\n",
        "mountaincar_noise_config = {\"env_name\": \"mountaincar_noise\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKDasf9uJ616"
      },
      "source": [
        "# *** YOU CAN EDIT THIS CELL ***\n",
        "# EXAMPLE\n",
        "class RandomAgent:\n",
        "    def __init__(self, agent_config={}):\n",
        "        self.config = agent_config\n",
        "        self.env_name = self.config['env_name']\n",
        "\n",
        "    def get_action(self, state):\n",
        "        action = np.random.choice(2)\n",
        "        return action\n",
        "    \n",
        "    def learn(self, state, action, reward, next_state, done):\n",
        "        if ('BAR' in self.config):\n",
        "            if (self.config['BAR']):\n",
        "                self.config['FOO'] += 1\n",
        "\n",
        "    def get_state(self, observation):\n",
        "        # In this function you're allowed to use \n",
        "        # the environment name for observation preprocessing\n",
        "        # Do not use it anywhere else\n",
        "        if self.env_name == 'catch':\n",
        "          state = observation\n",
        "        elif self.env_name == 'catch_noise':\n",
        "          state = observation\n",
        "        elif self.env_name == 'cartpole':\n",
        "          state = observation\n",
        "        elif self.env_name == 'cartpole_noise':\n",
        "          state = observation\n",
        "        elif self.env_name == 'mountaincar':\n",
        "          state = observation\n",
        "        elif self.env_name == 'mountaincar_noise':\n",
        "          state = observation\n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "\n",
        "        return state\n",
        "\n",
        "env1_config = {\n",
        "    \"env_name\": 'cartpole',\n",
        "    'FOO': 0.1,\n",
        "    'BAR': True\n",
        "}\n",
        "\n",
        "env2_config = {\n",
        "    \"env_name\": 'cartpole',\n",
        "    'FOO': 0.2,\n",
        "    'BAR': False\n",
        "}\n",
        "\n",
        "randomAgent1 = RandomAgent(agent_config=env1_config)\n",
        "randomAgent2 = RandomAgent(agent_config=env2_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEJ4SY1Db0_1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03VxMxVtmFbr"
      },
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "def get_theta(coss,sinn):\n",
        "  a_acos = math.acos(coss)\n",
        "  if sinn < 0:\n",
        "    angle = math.degrees(-a_acos) % 360\n",
        "  else: \n",
        "    angle = math.degrees(a_acos)\n",
        "  if(angle > 180):\n",
        "    angle -= 360\n",
        "  return angle\n",
        "\n",
        "class Agent47:\n",
        "    def __init__(self, agent_config={}):\n",
        "        self.config = agent_config\n",
        "        self.env_name = self.config['env_name']\n",
        "        \n",
        "        self.q_values = {}\n",
        "        self.states = []\n",
        "        self.actions_cnt = 3\n",
        "        self.steps = 1\n",
        "        self.ma = []\n",
        "        self.mn = []\n",
        "\n",
        "        #TUNABLES\n",
        "        self.epsilon = 0.8\n",
        "        self.nums = []\n",
        "        # self.min_beta = 0.1\n",
        "        self.beta = 0.9\n",
        "        self.discount = 0.9\n",
        "        self.adavalue = 25\n",
        "        \n",
        "        self.initialise_q()\n",
        "        self.explr_cnt = 0\n",
        "\n",
        "    def initialise_q(self):\n",
        "        if self.env_name == 'catch' or self.env_name == 'catch_noise':\n",
        "          state = observation\n",
        "\n",
        "        elif self.env_name == 'cartpole' or self.env_name == 'cartpole_noise':\n",
        "          self.mn = [-1., -5., -45., -5., 0.]\n",
        "          self.ma = [1., 5., 45., 5., 1.]\n",
        "          self.nums = [2 ,20, 6, 20, 1,2]\n",
        "\n",
        "        elif self.env_name == 'mountaincar' or self.env_name == 'mountaincar_noise':\n",
        "          self.mn = [-1.2, -0.07, 0.] \n",
        "          self.ma = [ 0.6, 0.07, 1.]\n",
        "          self.nums = [20, 20]\n",
        "\n",
        "        self.recurse(0, [])\n",
        "        for s in self.states:\n",
        "          for act in range(self.actions_cnt):\n",
        "            self.q_values[(s, act)] = 0\n",
        "            if ((self.env_name=='cartpole' or self.env_name=='cartpole_noise') and (s[2] == 0 or s[2] ==self.nums[2]-1)):\n",
        "              self.q_values[(s,act)] = -10000\n",
        "            elif (self.env_name=='mountaincar' or self.env_name=='mountaincar_noise'):\n",
        "              self.q_values[(s,act)] = (s[1] - self.nums[1]/2)*(act - 1)*100\n",
        "            else :\n",
        "              self.q_values[(s,act)] = 0\n",
        "            # if (s[len(self.nums)-1] == 0):\n",
        "            #   self.q_values[(s,act)] = -20 \n",
        "            # elif (s[len(self.nums)-1] == 1):\n",
        "            #   self.q_values[(s,act)] = 0\n",
        "            # elif (s[len(self.nums)-1] == 2):\n",
        "            #   self.q_values[(s,act)] = 7\n",
        "            # else:\n",
        "            #   self.q_values[(s,act)] = 15\n",
        "\n",
        "    def recurse(self, index, state):\n",
        "        if ( index == len(self.nums)):\n",
        "          self.states.append(tuple(state))          \n",
        "          return\n",
        "        for i in range(self.nums[index]+1):\n",
        "          state.append(i)\n",
        "          self.recurse(index+1,state)\n",
        "          state.pop()\n",
        "        \n",
        "    def get_action(self, state):\n",
        "        p = random.uniform(0, 1)\n",
        "        if (p <= self.epsilon):\n",
        "          self.explr_cnt += 1\n",
        "          return np.random.choice(3)\n",
        "        else:\n",
        "          act = []\n",
        "          mn = -100000000000\n",
        "          for action in range(self.actions_cnt):\n",
        "            if (mn < self.q_values[(state,action)]):\n",
        "              act = [action]\n",
        "              mn = self.q_values[(state,action)]\n",
        "            elif (mn == self.q_values[(state,action)]):\n",
        "              act.append(action)\n",
        "\n",
        "          #print(state,act, self.q_values[(state,act)])\n",
        "          idx = np.random.choice(len(act))\n",
        "          # print(act[idx])\n",
        "          return act[idx]\n",
        "\n",
        "    def learn(self, state, action, reward, next_state, done):\n",
        "\n",
        "        mxq = -100000000000\n",
        "        for action in range(self.actions_cnt):\n",
        "          if (mxq < self.q_values[(next_state, action)]):\n",
        "            mxq = self.q_values[(next_state, action)]\n",
        "        self.q_values[(state, action)] -=  self.beta * (reward + self.discount * mxq - self.q_values[(state, action)])\n",
        "\n",
        "        if (done):\n",
        "          self.steps += 1\n",
        "          print(state, self.explr_cnt)\n",
        "          self.explr_cnt = 0\n",
        "          ##TUNABLE\n",
        "          # if(self.steps > 100):\n",
        "          self.epsilon -= self.epsilon/100\n",
        "          self.beta -= self.beta/1000\n",
        "\n",
        "    def get_state(self, observation):\n",
        "        # In this function you're allowed to use \n",
        "        # the environment name for observation preprocessing\n",
        "        # Do not use it anywhere else\n",
        "        if self.env_name == 'catch' or self.env_name == 'catch_noise':\n",
        "          state = observation\n",
        "        \n",
        "        elif self.env_name == 'cartpole' or self.env_name == 'cartpole_noise':\n",
        "          mn = self.mn\n",
        "          ma = self.ma\n",
        "          nums = self.nums\n",
        "          index = 0\n",
        "          state = [0, 0, 0, 0 ,0]\n",
        "          state[0] = int(( (observation[0][0] - mn[0])/(ma[0] - mn[0]) )*nums[0])\n",
        "          state[1] = int(( (observation[0][1] - mn[1])/(ma[1] - mn[1]) )*nums[1])\n",
        "          state[2] = int(( (get_theta(observation[0][3],observation[0][2]) - mn[2])/(ma[2] - mn[2]) )*nums[2])\n",
        "          state[3] = int(( (observation[0][4] - mn[3])/(ma[3] - mn[3]) )*nums[3])\n",
        "          state = tuple(state)\n",
        "\n",
        "        elif self.env_name == 'mountaincar' or self.env_name == 'mountaincar_noise':\n",
        "          mn = self.mn\n",
        "          ma = self.ma\n",
        "          nums = self.nums\n",
        "          state = [0, 0]\n",
        "          for i in range(len(observation[0])-1):\n",
        "            state[i] = int(( (observation[0][i] - mn[i])/(ma[i] - mn[i]) )*nums[i])\n",
        "          state = tuple(state)\n",
        "        \n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "        return state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "288e54f50bdc46cfb197ae5cd249df30",
            "a8c036a335214549bdf71fa24aa089d4",
            "c2a6edac58a240d78bf79ad051aab668",
            "93ccefe8a10c44e2a4fd04dd7e62757c",
            "18b62fef395d4acfa8943ab14335a3ef",
            "42200ccfe3cb44f8afd295a76a1ddaa7",
            "7e6a10099b6545969db83b67b5949f69",
            "e66d09719f7145c1b7e24ace22337db1",
            "52170d3e27c549bca00a2691d9393d12",
            "e5219adff68045439e547de906f14e8e",
            "f72fdcecaa9940f7b4730ab3eb6c8762"
          ]
        },
        "id": "Om6NjfVAsHTD",
        "outputId": "7b037d92-9393-411d-8b26-c7207a1597f8"
      },
      "source": [
        "# *** YOU CAN EDIT THIS CELL ***\n",
        "# TEST AREA\n",
        "env = environments.load_env(environments.MOUNTAINCAR)  # replace 'environments.CARTPOLE' with other environments\n",
        "\n",
        "agent = Agent47(agent_config={\"env_name\": 'mountaincar'})    # replace with 'RandomAgent()' to use your custom agent\n",
        "\n",
        "NUM_EPISODES = 1000                        # replace with 'env.bsuite_num_episodes' to run for pre-specified number of episodes\n",
        "for episode_n in tqdm(range(NUM_EPISODES)):\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "    episode_moves = 0\n",
        " \n",
        "    observation = env.reset()\n",
        "    state = agent.get_state(observation)\n",
        "\n",
        "    while not done:\n",
        "        action = agent.get_action(state)\n",
        "        next_observation, reward, done, _ = env.step(action)\n",
        "        next_state = agent.get_state(next_observation)\n",
        "\n",
        "        agent.learn(state, action, reward, next_state, done)\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "        episode_reward += reward\n",
        "        episode_moves += 1\n",
        "        # if(episode_n == NUM_EPISODES-1):\n",
        "        #   print(state, action)\n",
        "    if (((episode_n+1) % 1) == 0): \n",
        "        print(\"EPISODE: \",episode_n+1,\"\\tREWARD: \",episode_reward,\"\\tEPISODE_LENGTH: \",episode_moves)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[37mLoaded bsuite_id: mountain_car/0.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "288e54f50bdc46cfb197ae5cd249df30",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(18, 11) 490\n",
            "EPISODE:  1 \tREWARD:  -604.0 \tEPISODE_LENGTH:  604\n",
            "(18, 14) 422\n",
            "EPISODE:  2 \tREWARD:  -535.0 \tEPISODE_LENGTH:  535\n",
            "(18, 12) 431\n",
            "EPISODE:  3 \tREWARD:  -548.0 \tEPISODE_LENGTH:  548\n",
            "(18, 11) 587\n",
            "EPISODE:  4 \tREWARD:  -759.0 \tEPISODE_LENGTH:  759\n",
            "(18, 11) 391\n",
            "EPISODE:  5 \tREWARD:  -496.0 \tEPISODE_LENGTH:  496\n",
            "(3, 15) 767\n",
            "EPISODE:  6 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(0, 11) 768\n",
            "EPISODE:  7 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 12) 382\n",
            "EPISODE:  8 \tREWARD:  -505.0 \tEPISODE_LENGTH:  505\n",
            "(7, 16) 761\n",
            "EPISODE:  9 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 12) 337\n",
            "EPISODE:  10 \tREWARD:  -459.0 \tEPISODE_LENGTH:  459\n",
            "(18, 13) 541\n",
            "EPISODE:  11 \tREWARD:  -761.0 \tEPISODE_LENGTH:  761\n",
            "(18, 13) 394\n",
            "EPISODE:  12 \tREWARD:  -549.0 \tEPISODE_LENGTH:  549\n",
            "(18, 11) 602\n",
            "EPISODE:  13 \tREWARD:  -831.0 \tEPISODE_LENGTH:  831\n",
            "(14, 6) 715\n",
            "EPISODE:  14 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 12) 382\n",
            "EPISODE:  15 \tREWARD:  -534.0 \tEPISODE_LENGTH:  534\n",
            "(17, 11) 728\n",
            "EPISODE:  16 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 11) 259\n",
            "EPISODE:  17 \tREWARD:  -378.0 \tEPISODE_LENGTH:  378\n",
            "(18, 11) 554\n",
            "EPISODE:  18 \tREWARD:  -790.0 \tEPISODE_LENGTH:  790\n",
            "(18, 12) 505\n",
            "EPISODE:  19 \tREWARD:  -776.0 \tEPISODE_LENGTH:  776\n",
            "(18, 11) 325\n",
            "EPISODE:  20 \tREWARD:  -510.0 \tEPISODE_LENGTH:  510\n",
            "(18, 11) 201\n",
            "EPISODE:  21 \tREWARD:  -336.0 \tEPISODE_LENGTH:  336\n",
            "(18, 12) 208\n",
            "EPISODE:  22 \tREWARD:  -349.0 \tEPISODE_LENGTH:  349\n",
            "(18, 11) 513\n",
            "EPISODE:  23 \tREWARD:  -815.0 \tEPISODE_LENGTH:  815\n",
            "(18, 13) 369\n",
            "EPISODE:  24 \tREWARD:  -584.0 \tEPISODE_LENGTH:  584\n",
            "(18, 12) 227\n",
            "EPISODE:  25 \tREWARD:  -374.0 \tEPISODE_LENGTH:  374\n",
            "(18, 12) 221\n",
            "EPISODE:  26 \tREWARD:  -360.0 \tEPISODE_LENGTH:  360\n",
            "(18, 11) 427\n",
            "EPISODE:  27 \tREWARD:  -695.0 \tEPISODE_LENGTH:  695\n",
            "(18, 13) 386\n",
            "EPISODE:  28 \tREWARD:  -628.0 \tEPISODE_LENGTH:  628\n",
            "(18, 11) 363\n",
            "EPISODE:  29 \tREWARD:  -610.0 \tEPISODE_LENGTH:  610\n",
            "(18, 12) 256\n",
            "EPISODE:  30 \tREWARD:  -448.0 \tEPISODE_LENGTH:  448\n",
            "(18, 14) 203\n",
            "EPISODE:  31 \tREWARD:  -364.0 \tEPISODE_LENGTH:  364\n",
            "(18, 13) 250\n",
            "EPISODE:  32 \tREWARD:  -420.0 \tEPISODE_LENGTH:  420\n",
            "(18, 11) 361\n",
            "EPISODE:  33 \tREWARD:  -619.0 \tEPISODE_LENGTH:  619\n",
            "(18, 11) 157\n",
            "EPISODE:  34 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 12) 481\n",
            "EPISODE:  35 \tREWARD:  -854.0 \tEPISODE_LENGTH:  854\n",
            "(18, 12) 205\n",
            "EPISODE:  36 \tREWARD:  -342.0 \tEPISODE_LENGTH:  342\n",
            "(18, 11) 288\n",
            "EPISODE:  37 \tREWARD:  -516.0 \tEPISODE_LENGTH:  516\n",
            "(18, 11) 291\n",
            "EPISODE:  38 \tREWARD:  -521.0 \tEPISODE_LENGTH:  521\n",
            "(18, 12) 241\n",
            "EPISODE:  39 \tREWARD:  -436.0 \tEPISODE_LENGTH:  436\n",
            "(18, 12) 534\n",
            "EPISODE:  40 \tREWARD:  -952.0 \tEPISODE_LENGTH:  952\n",
            "(18, 12) 227\n",
            "EPISODE:  41 \tREWARD:  -447.0 \tEPISODE_LENGTH:  447\n",
            "(12, 2) 506\n",
            "EPISODE:  42 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 11) 253\n",
            "EPISODE:  43 \tREWARD:  -458.0 \tEPISODE_LENGTH:  458\n",
            "(18, 12) 308\n",
            "EPISODE:  44 \tREWARD:  -624.0 \tEPISODE_LENGTH:  624\n",
            "(18, 12) 385\n",
            "EPISODE:  45 \tREWARD:  -777.0 \tEPISODE_LENGTH:  777\n",
            "(2, 14) 507\n",
            "EPISODE:  46 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 11) 186\n",
            "EPISODE:  47 \tREWARD:  -342.0 \tEPISODE_LENGTH:  342\n",
            "(18, 11) 307\n",
            "EPISODE:  48 \tREWARD:  -610.0 \tEPISODE_LENGTH:  610\n",
            "(18, 12) 270\n",
            "EPISODE:  49 \tREWARD:  -546.0 \tEPISODE_LENGTH:  546\n",
            "(18, 13) 345\n",
            "EPISODE:  50 \tREWARD:  -688.0 \tEPISODE_LENGTH:  688\n",
            "(18, 12) 211\n",
            "EPISODE:  51 \tREWARD:  -435.0 \tEPISODE_LENGTH:  435\n",
            "(18, 11) 177\n",
            "EPISODE:  52 \tREWARD:  -356.0 \tEPISODE_LENGTH:  356\n",
            "(18, 12) 117\n",
            "EPISODE:  53 \tREWARD:  -256.0 \tEPISODE_LENGTH:  256\n",
            "(18, 11) 194\n",
            "EPISODE:  54 \tREWARD:  -432.0 \tEPISODE_LENGTH:  432\n",
            "(18, 12) 194\n",
            "EPISODE:  55 \tREWARD:  -438.0 \tEPISODE_LENGTH:  438\n",
            "(18, 10) 330\n",
            "EPISODE:  56 \tREWARD:  -673.0 \tEPISODE_LENGTH:  673\n",
            "(18, 12) 113\n",
            "EPISODE:  57 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 12) 240\n",
            "EPISODE:  58 \tREWARD:  -532.0 \tEPISODE_LENGTH:  532\n",
            "(18, 11) 141\n",
            "EPISODE:  59 \tREWARD:  -338.0 \tEPISODE_LENGTH:  338\n",
            "(18, 11) 151\n",
            "EPISODE:  60 \tREWARD:  -324.0 \tEPISODE_LENGTH:  324\n",
            "(18, 12) 225\n",
            "EPISODE:  61 \tREWARD:  -497.0 \tEPISODE_LENGTH:  497\n",
            "(18, 12) 258\n",
            "EPISODE:  62 \tREWARD:  -670.0 \tEPISODE_LENGTH:  670\n",
            "(18, 12) 135\n",
            "EPISODE:  63 \tREWARD:  -337.0 \tEPISODE_LENGTH:  337\n",
            "(18, 11) 123\n",
            "EPISODE:  64 \tREWARD:  -318.0 \tEPISODE_LENGTH:  318\n",
            "(18, 12) 176\n",
            "EPISODE:  65 \tREWARD:  -435.0 \tEPISODE_LENGTH:  435\n",
            "(18, 11) 227\n",
            "EPISODE:  66 \tREWARD:  -533.0 \tEPISODE_LENGTH:  533\n",
            "(18, 11) 192\n",
            "EPISODE:  67 \tREWARD:  -467.0 \tEPISODE_LENGTH:  467\n",
            "(18, 12) 86\n",
            "EPISODE:  68 \tREWARD:  -267.0 \tEPISODE_LENGTH:  267\n",
            "(18, 11) 110\n",
            "EPISODE:  69 \tREWARD:  -256.0 \tEPISODE_LENGTH:  256\n",
            "(18, 12) 154\n",
            "EPISODE:  70 \tREWARD:  -369.0 \tEPISODE_LENGTH:  369\n",
            "(18, 11) 112\n",
            "EPISODE:  71 \tREWARD:  -263.0 \tEPISODE_LENGTH:  263\n",
            "(18, 12) 97\n",
            "EPISODE:  72 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 11) 109\n",
            "EPISODE:  73 \tREWARD:  -275.0 \tEPISODE_LENGTH:  275\n",
            "(18, 11) 170\n",
            "EPISODE:  74 \tREWARD:  -431.0 \tEPISODE_LENGTH:  431\n",
            "(18, 12) 97\n",
            "EPISODE:  75 \tREWARD:  -263.0 \tEPISODE_LENGTH:  263\n",
            "(18, 10) 239\n",
            "EPISODE:  76 \tREWARD:  -584.0 \tEPISODE_LENGTH:  584\n",
            "(18, 11) 181\n",
            "EPISODE:  77 \tREWARD:  -450.0 \tEPISODE_LENGTH:  450\n",
            "(18, 12) 212\n",
            "EPISODE:  78 \tREWARD:  -623.0 \tEPISODE_LENGTH:  623\n",
            "(18, 12) 114\n",
            "EPISODE:  79 \tREWARD:  -353.0 \tEPISODE_LENGTH:  353\n",
            "(18, 12) 171\n",
            "EPISODE:  80 \tREWARD:  -442.0 \tEPISODE_LENGTH:  442\n",
            "(18, 13) 99\n",
            "EPISODE:  81 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 12) 96\n",
            "EPISODE:  82 \tREWARD:  -265.0 \tEPISODE_LENGTH:  265\n",
            "(18, 11) 108\n",
            "EPISODE:  83 \tREWARD:  -290.0 \tEPISODE_LENGTH:  290\n",
            "(18, 12) 167\n",
            "EPISODE:  84 \tREWARD:  -436.0 \tEPISODE_LENGTH:  436\n",
            "(18, 11) 89\n",
            "EPISODE:  85 \tREWARD:  -245.0 \tEPISODE_LENGTH:  245\n",
            "(18, 12) 148\n",
            "EPISODE:  86 \tREWARD:  -445.0 \tEPISODE_LENGTH:  445\n",
            "(18, 12) 68\n",
            "EPISODE:  87 \tREWARD:  -246.0 \tEPISODE_LENGTH:  246\n",
            "(18, 12) 77\n",
            "EPISODE:  88 \tREWARD:  -268.0 \tEPISODE_LENGTH:  268\n",
            "(18, 12) 172\n",
            "EPISODE:  89 \tREWARD:  -548.0 \tEPISODE_LENGTH:  548\n",
            "(18, 12) 56\n",
            "EPISODE:  90 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 146\n",
            "EPISODE:  91 \tREWARD:  -431.0 \tEPISODE_LENGTH:  431\n",
            "(18, 12) 80\n",
            "EPISODE:  92 \tREWARD:  -248.0 \tEPISODE_LENGTH:  248\n",
            "(18, 12) 104\n",
            "EPISODE:  93 \tREWARD:  -318.0 \tEPISODE_LENGTH:  318\n",
            "(18, 12) 43\n",
            "EPISODE:  94 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 11) 64\n",
            "EPISODE:  95 \tREWARD:  -248.0 \tEPISODE_LENGTH:  248\n",
            "(18, 12) 68\n",
            "EPISODE:  96 \tREWARD:  -257.0 \tEPISODE_LENGTH:  257\n",
            "(18, 12) 84\n",
            "EPISODE:  97 \tREWARD:  -258.0 \tEPISODE_LENGTH:  258\n",
            "(18, 12) 58\n",
            "EPISODE:  98 \tREWARD:  -230.0 \tEPISODE_LENGTH:  230\n",
            "(18, 12) 46\n",
            "EPISODE:  99 \tREWARD:  -179.0 \tEPISODE_LENGTH:  179\n",
            "(18, 12) 98\n",
            "EPISODE:  100 \tREWARD:  -362.0 \tEPISODE_LENGTH:  362\n",
            "(18, 11) 66\n",
            "EPISODE:  101 \tREWARD:  -259.0 \tEPISODE_LENGTH:  259\n",
            "(18, 12) 94\n",
            "EPISODE:  102 \tREWARD:  -349.0 \tEPISODE_LENGTH:  349\n",
            "(18, 11) 48\n",
            "EPISODE:  103 \tREWARD:  -180.0 \tEPISODE_LENGTH:  180\n",
            "(18, 13) 84\n",
            "EPISODE:  104 \tREWARD:  -255.0 \tEPISODE_LENGTH:  255\n",
            "(18, 12) 79\n",
            "EPISODE:  105 \tREWARD:  -286.0 \tEPISODE_LENGTH:  286\n",
            "(18, 12) 72\n",
            "EPISODE:  106 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 80\n",
            "EPISODE:  107 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 12) 73\n",
            "EPISODE:  108 \tREWARD:  -266.0 \tEPISODE_LENGTH:  266\n",
            "(18, 11) 54\n",
            "EPISODE:  109 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 11) 52\n",
            "EPISODE:  110 \tREWARD:  -188.0 \tEPISODE_LENGTH:  188\n",
            "(18, 12) 68\n",
            "EPISODE:  111 \tREWARD:  -260.0 \tEPISODE_LENGTH:  260\n",
            "(18, 12) 71\n",
            "EPISODE:  112 \tREWARD:  -263.0 \tEPISODE_LENGTH:  263\n",
            "(18, 12) 50\n",
            "EPISODE:  113 \tREWARD:  -179.0 \tEPISODE_LENGTH:  179\n",
            "(18, 12) 67\n",
            "EPISODE:  114 \tREWARD:  -257.0 \tEPISODE_LENGTH:  257\n",
            "(18, 12) 71\n",
            "EPISODE:  115 \tREWARD:  -283.0 \tEPISODE_LENGTH:  283\n",
            "(18, 13) 43\n",
            "EPISODE:  116 \tREWARD:  -183.0 \tEPISODE_LENGTH:  183\n",
            "(18, 13) 83\n",
            "EPISODE:  117 \tREWARD:  -340.0 \tEPISODE_LENGTH:  340\n",
            "(18, 12) 67\n",
            "EPISODE:  118 \tREWARD:  -279.0 \tEPISODE_LENGTH:  279\n",
            "(18, 11) 61\n",
            "EPISODE:  119 \tREWARD:  -261.0 \tEPISODE_LENGTH:  261\n",
            "(18, 11) 57\n",
            "EPISODE:  120 \tREWARD:  -261.0 \tEPISODE_LENGTH:  261\n",
            "(18, 12) 91\n",
            "EPISODE:  121 \tREWARD:  -369.0 \tEPISODE_LENGTH:  369\n",
            "(18, 12) 40\n",
            "EPISODE:  122 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 12) 36\n",
            "EPISODE:  123 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 12) 67\n",
            "EPISODE:  124 \tREWARD:  -247.0 \tEPISODE_LENGTH:  247\n",
            "(18, 11) 55\n",
            "EPISODE:  125 \tREWARD:  -264.0 \tEPISODE_LENGTH:  264\n",
            "(18, 12) 78\n",
            "EPISODE:  126 \tREWARD:  -364.0 \tEPISODE_LENGTH:  364\n",
            "(18, 12) 66\n",
            "EPISODE:  127 \tREWARD:  -288.0 \tEPISODE_LENGTH:  288\n",
            "(18, 12) 62\n",
            "EPISODE:  128 \tREWARD:  -241.0 \tEPISODE_LENGTH:  241\n",
            "(18, 12) 31\n",
            "EPISODE:  129 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 12) 50\n",
            "EPISODE:  130 \tREWARD:  -245.0 \tEPISODE_LENGTH:  245\n",
            "(18, 11) 56\n",
            "EPISODE:  131 \tREWARD:  -262.0 \tEPISODE_LENGTH:  262\n",
            "(18, 12) 28\n",
            "EPISODE:  132 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 11) 60\n",
            "EPISODE:  133 \tREWARD:  -261.0 \tEPISODE_LENGTH:  261\n",
            "(18, 12) 68\n",
            "EPISODE:  134 \tREWARD:  -341.0 \tEPISODE_LENGTH:  341\n",
            "(18, 12) 38\n",
            "EPISODE:  135 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 14) 57\n",
            "EPISODE:  136 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 11) 61\n",
            "EPISODE:  137 \tREWARD:  -288.0 \tEPISODE_LENGTH:  288\n",
            "(18, 13) 38\n",
            "EPISODE:  138 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 12) 30\n",
            "EPISODE:  139 \tREWARD:  -175.0 \tEPISODE_LENGTH:  175\n",
            "(18, 13) 45\n",
            "EPISODE:  140 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 12) 32\n",
            "EPISODE:  141 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 14) 69\n",
            "EPISODE:  142 \tREWARD:  -343.0 \tEPISODE_LENGTH:  343\n",
            "(18, 13) 54\n",
            "EPISODE:  143 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 32\n",
            "EPISODE:  144 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 12) 29\n",
            "EPISODE:  145 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 12) 31\n",
            "EPISODE:  146 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 12) 40\n",
            "EPISODE:  147 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 11) 33\n",
            "EPISODE:  148 \tREWARD:  -179.0 \tEPISODE_LENGTH:  179\n",
            "(18, 11) 32\n",
            "EPISODE:  149 \tREWARD:  -177.0 \tEPISODE_LENGTH:  177\n",
            "(18, 13) 25\n",
            "EPISODE:  150 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 12) 33\n",
            "EPISODE:  151 \tREWARD:  -206.0 \tEPISODE_LENGTH:  206\n",
            "(18, 13) 25\n",
            "EPISODE:  152 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 52\n",
            "EPISODE:  153 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 11) 27\n",
            "EPISODE:  154 \tREWARD:  -182.0 \tEPISODE_LENGTH:  182\n",
            "(18, 12) 36\n",
            "EPISODE:  155 \tREWARD:  -247.0 \tEPISODE_LENGTH:  247\n",
            "(18, 11) 31\n",
            "EPISODE:  156 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 11) 36\n",
            "EPISODE:  157 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 12) 26\n",
            "EPISODE:  158 \tREWARD:  -173.0 \tEPISODE_LENGTH:  173\n",
            "(18, 12) 44\n",
            "EPISODE:  159 \tREWARD:  -258.0 \tEPISODE_LENGTH:  258\n",
            "(18, 12) 40\n",
            "EPISODE:  160 \tREWARD:  -247.0 \tEPISODE_LENGTH:  247\n",
            "(18, 11) 38\n",
            "EPISODE:  161 \tREWARD:  -201.0 \tEPISODE_LENGTH:  201\n",
            "(18, 14) 28\n",
            "EPISODE:  162 \tREWARD:  -160.0 \tEPISODE_LENGTH:  160\n",
            "(18, 12) 27\n",
            "EPISODE:  163 \tREWARD:  -178.0 \tEPISODE_LENGTH:  178\n",
            "(18, 12) 27\n",
            "EPISODE:  164 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 11) 38\n",
            "EPISODE:  165 \tREWARD:  -185.0 \tEPISODE_LENGTH:  185\n",
            "(18, 12) 35\n",
            "EPISODE:  166 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 25\n",
            "EPISODE:  167 \tREWARD:  -213.0 \tEPISODE_LENGTH:  213\n",
            "(18, 12) 36\n",
            "EPISODE:  168 \tREWARD:  -258.0 \tEPISODE_LENGTH:  258\n",
            "(18, 12) 28\n",
            "EPISODE:  169 \tREWARD:  -178.0 \tEPISODE_LENGTH:  178\n",
            "(18, 12) 30\n",
            "EPISODE:  170 \tREWARD:  -189.0 \tEPISODE_LENGTH:  189\n",
            "(18, 11) 34\n",
            "EPISODE:  171 \tREWARD:  -179.0 \tEPISODE_LENGTH:  179\n",
            "(18, 11) 32\n",
            "EPISODE:  172 \tREWARD:  -206.0 \tEPISODE_LENGTH:  206\n",
            "(18, 12) 25\n",
            "EPISODE:  173 \tREWARD:  -179.0 \tEPISODE_LENGTH:  179\n",
            "(18, 13) 51\n",
            "EPISODE:  174 \tREWARD:  -352.0 \tEPISODE_LENGTH:  352\n",
            "(18, 13) 28\n",
            "EPISODE:  175 \tREWARD:  -177.0 \tEPISODE_LENGTH:  177\n",
            "(18, 12) 29\n",
            "EPISODE:  176 \tREWARD:  -188.0 \tEPISODE_LENGTH:  188\n",
            "(18, 12) 24\n",
            "EPISODE:  177 \tREWARD:  -182.0 \tEPISODE_LENGTH:  182\n",
            "(18, 13) 37\n",
            "EPISODE:  178 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 12) 15\n",
            "EPISODE:  179 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 32\n",
            "EPISODE:  180 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 12) 36\n",
            "EPISODE:  181 \tREWARD:  -255.0 \tEPISODE_LENGTH:  255\n",
            "(18, 12) 25\n",
            "EPISODE:  182 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 12) 14\n",
            "EPISODE:  183 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 12) 21\n",
            "EPISODE:  184 \tREWARD:  -181.0 \tEPISODE_LENGTH:  181\n",
            "(18, 12) 16\n",
            "EPISODE:  185 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 12) 23\n",
            "EPISODE:  186 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 12) 20\n",
            "EPISODE:  187 \tREWARD:  -173.0 \tEPISODE_LENGTH:  173\n",
            "(18, 13) 13\n",
            "EPISODE:  188 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 11\n",
            "EPISODE:  189 \tREWARD:  -163.0 \tEPISODE_LENGTH:  163\n",
            "(18, 12) 19\n",
            "EPISODE:  190 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 12) 13\n",
            "EPISODE:  191 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 12) 33\n",
            "EPISODE:  192 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 12) 12\n",
            "EPISODE:  193 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 18\n",
            "EPISODE:  194 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 12) 15\n",
            "EPISODE:  195 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 12) 17\n",
            "EPISODE:  196 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 11) 21\n",
            "EPISODE:  197 \tREWARD:  -173.0 \tEPISODE_LENGTH:  173\n",
            "(18, 12) 17\n",
            "EPISODE:  198 \tREWARD:  -194.0 \tEPISODE_LENGTH:  194\n",
            "(18, 12) 20\n",
            "EPISODE:  199 \tREWARD:  -257.0 \tEPISODE_LENGTH:  257\n",
            "(18, 12) 15\n",
            "EPISODE:  200 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 12) 36\n",
            "EPISODE:  201 \tREWARD:  -276.0 \tEPISODE_LENGTH:  276\n",
            "(18, 13) 15\n",
            "EPISODE:  202 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 12\n",
            "EPISODE:  203 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 12) 13\n",
            "EPISODE:  204 \tREWARD:  -175.0 \tEPISODE_LENGTH:  175\n",
            "(18, 12) 13\n",
            "EPISODE:  205 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 11) 27\n",
            "EPISODE:  206 \tREWARD:  -268.0 \tEPISODE_LENGTH:  268\n",
            "(18, 11) 23\n",
            "EPISODE:  207 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 12) 14\n",
            "EPISODE:  208 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 12) 20\n",
            "EPISODE:  209 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 13) 23\n",
            "EPISODE:  210 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 18\n",
            "EPISODE:  211 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 27\n",
            "EPISODE:  212 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 12) 20\n",
            "EPISODE:  213 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 17\n",
            "EPISODE:  214 \tREWARD:  -178.0 \tEPISODE_LENGTH:  178\n",
            "(18, 12) 23\n",
            "EPISODE:  215 \tREWARD:  -233.0 \tEPISODE_LENGTH:  233\n",
            "(18, 13) 14\n",
            "EPISODE:  216 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 12) 13\n",
            "EPISODE:  217 \tREWARD:  -177.0 \tEPISODE_LENGTH:  177\n",
            "(18, 13) 21\n",
            "EPISODE:  218 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 13\n",
            "EPISODE:  219 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 12\n",
            "EPISODE:  220 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 12\n",
            "EPISODE:  221 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 10\n",
            "EPISODE:  222 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 11) 31\n",
            "EPISODE:  223 \tREWARD:  -256.0 \tEPISODE_LENGTH:  256\n",
            "(18, 13) 19\n",
            "EPISODE:  224 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 12) 17\n",
            "EPISODE:  225 \tREWARD:  -175.0 \tEPISODE_LENGTH:  175\n",
            "(18, 12) 19\n",
            "EPISODE:  226 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 12) 13\n",
            "EPISODE:  227 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 12) 21\n",
            "EPISODE:  228 \tREWARD:  -247.0 \tEPISODE_LENGTH:  247\n",
            "(18, 12) 11\n",
            "EPISODE:  229 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 12) 18\n",
            "EPISODE:  230 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 11) 14\n",
            "EPISODE:  231 \tREWARD:  -194.0 \tEPISODE_LENGTH:  194\n",
            "(18, 13) 13\n",
            "EPISODE:  232 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 13) 13\n",
            "EPISODE:  233 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 28\n",
            "EPISODE:  234 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 12) 14\n",
            "EPISODE:  235 \tREWARD:  -178.0 \tEPISODE_LENGTH:  178\n",
            "(18, 13) 28\n",
            "EPISODE:  236 \tREWARD:  -262.0 \tEPISODE_LENGTH:  262\n",
            "(18, 12) 16\n",
            "EPISODE:  237 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 13) 8\n",
            "EPISODE:  238 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 15\n",
            "EPISODE:  239 \tREWARD:  -177.0 \tEPISODE_LENGTH:  177\n",
            "(18, 13) 16\n",
            "EPISODE:  240 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 13\n",
            "EPISODE:  241 \tREWARD:  -163.0 \tEPISODE_LENGTH:  163\n",
            "(18, 13) 11\n",
            "EPISODE:  242 \tREWARD:  -243.0 \tEPISODE_LENGTH:  243\n",
            "(18, 12) 15\n",
            "EPISODE:  243 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 1\n",
            "EPISODE:  244 \tREWARD:  -173.0 \tEPISODE_LENGTH:  173\n",
            "(18, 13) 12\n",
            "EPISODE:  245 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 11) 10\n",
            "EPISODE:  246 \tREWARD:  -175.0 \tEPISODE_LENGTH:  175\n",
            "(18, 12) 14\n",
            "EPISODE:  247 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 12) 17\n",
            "EPISODE:  248 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 12) 18\n",
            "EPISODE:  249 \tREWARD:  -243.0 \tEPISODE_LENGTH:  243\n",
            "(18, 12) 12\n",
            "EPISODE:  250 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 12) 6\n",
            "EPISODE:  251 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 12) 18\n",
            "EPISODE:  252 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 11\n",
            "EPISODE:  253 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 16\n",
            "EPISODE:  254 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 9\n",
            "EPISODE:  255 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 13) 22\n",
            "EPISODE:  256 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 13) 14\n",
            "EPISODE:  257 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 11) 12\n",
            "EPISODE:  258 \tREWARD:  -181.0 \tEPISODE_LENGTH:  181\n",
            "(18, 13) 4\n",
            "EPISODE:  259 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 9\n",
            "EPISODE:  260 \tREWARD:  -175.0 \tEPISODE_LENGTH:  175\n",
            "(18, 13) 8\n",
            "EPISODE:  261 \tREWARD:  -180.0 \tEPISODE_LENGTH:  180\n",
            "(18, 13) 8\n",
            "EPISODE:  262 \tREWARD:  -179.0 \tEPISODE_LENGTH:  179\n",
            "(18, 13) 15\n",
            "EPISODE:  263 \tREWARD:  -247.0 \tEPISODE_LENGTH:  247\n",
            "(18, 12) 8\n",
            "EPISODE:  264 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 7\n",
            "EPISODE:  265 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 6\n",
            "EPISODE:  266 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 7\n",
            "EPISODE:  267 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 12) 4\n",
            "EPISODE:  268 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 12) 16\n",
            "EPISODE:  269 \tREWARD:  -248.0 \tEPISODE_LENGTH:  248\n",
            "(18, 12) 11\n",
            "EPISODE:  270 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 5\n",
            "EPISODE:  271 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 12) 10\n",
            "EPISODE:  272 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 6\n",
            "EPISODE:  273 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 12\n",
            "EPISODE:  274 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 6\n",
            "EPISODE:  275 \tREWARD:  -173.0 \tEPISODE_LENGTH:  173\n",
            "(18, 13) 6\n",
            "EPISODE:  276 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 13\n",
            "EPISODE:  277 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 7\n",
            "EPISODE:  278 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 12) 8\n",
            "EPISODE:  279 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 11\n",
            "EPISODE:  280 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 3\n",
            "EPISODE:  281 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 13) 7\n",
            "EPISODE:  282 \tREWARD:  -163.0 \tEPISODE_LENGTH:  163\n",
            "(18, 12) 7\n",
            "EPISODE:  283 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 12\n",
            "EPISODE:  284 \tREWARD:  -263.0 \tEPISODE_LENGTH:  263\n",
            "(18, 13) 5\n",
            "EPISODE:  285 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 11) 10\n",
            "EPISODE:  286 \tREWARD:  -196.0 \tEPISODE_LENGTH:  196\n",
            "(18, 12) 12\n",
            "EPISODE:  287 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 12) 11\n",
            "EPISODE:  288 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 13) 6\n",
            "EPISODE:  289 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 6\n",
            "EPISODE:  290 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 10\n",
            "EPISODE:  291 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 17\n",
            "EPISODE:  292 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 7\n",
            "EPISODE:  293 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 5\n",
            "EPISODE:  294 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 13) 4\n",
            "EPISODE:  295 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 7\n",
            "EPISODE:  296 \tREWARD:  -264.0 \tEPISODE_LENGTH:  264\n",
            "(18, 13) 7\n",
            "EPISODE:  297 \tREWARD:  -192.0 \tEPISODE_LENGTH:  192\n",
            "(18, 13) 8\n",
            "EPISODE:  298 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 11\n",
            "EPISODE:  299 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 14) 10\n",
            "EPISODE:  300 \tREWARD:  -161.0 \tEPISODE_LENGTH:  161\n",
            "(18, 12) 5\n",
            "EPISODE:  301 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 2\n",
            "EPISODE:  302 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 12\n",
            "EPISODE:  303 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 12) 10\n",
            "EPISODE:  304 \tREWARD:  -185.0 \tEPISODE_LENGTH:  185\n",
            "(18, 13) 5\n",
            "EPISODE:  305 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 13) 6\n",
            "EPISODE:  306 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 13) 6\n",
            "EPISODE:  307 \tREWARD:  -177.0 \tEPISODE_LENGTH:  177\n",
            "(18, 13) 8\n",
            "EPISODE:  308 \tREWARD:  -250.0 \tEPISODE_LENGTH:  250\n",
            "(18, 11) 11\n",
            "EPISODE:  309 \tREWARD:  -181.0 \tEPISODE_LENGTH:  181\n",
            "(18, 12) 14\n",
            "EPISODE:  310 \tREWARD:  -248.0 \tEPISODE_LENGTH:  248\n",
            "(18, 13) 5\n",
            "EPISODE:  311 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 6\n",
            "EPISODE:  312 \tREWARD:  -173.0 \tEPISODE_LENGTH:  173\n",
            "(18, 12) 6\n",
            "EPISODE:  313 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 10\n",
            "EPISODE:  314 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 11) 6\n",
            "EPISODE:  315 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 4\n",
            "EPISODE:  316 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 12) 7\n",
            "EPISODE:  317 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 13) 5\n",
            "EPISODE:  318 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 4\n",
            "EPISODE:  319 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 6\n",
            "EPISODE:  320 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 2\n",
            "EPISODE:  321 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 12) 7\n",
            "EPISODE:  322 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 4\n",
            "EPISODE:  323 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 7\n",
            "EPISODE:  324 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 12) 6\n",
            "EPISODE:  325 \tREWARD:  -173.0 \tEPISODE_LENGTH:  173\n",
            "(18, 12) 7\n",
            "EPISODE:  326 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 4\n",
            "EPISODE:  327 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 7\n",
            "EPISODE:  328 \tREWARD:  -162.0 \tEPISODE_LENGTH:  162\n",
            "(18, 13) 3\n",
            "EPISODE:  329 \tREWARD:  -175.0 \tEPISODE_LENGTH:  175\n",
            "(18, 13) 9\n",
            "EPISODE:  330 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 5\n",
            "EPISODE:  331 \tREWARD:  -173.0 \tEPISODE_LENGTH:  173\n",
            "(18, 13) 4\n",
            "EPISODE:  332 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 3\n",
            "EPISODE:  333 \tREWARD:  -182.0 \tEPISODE_LENGTH:  182\n",
            "(18, 13) 7\n",
            "EPISODE:  334 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 6\n",
            "EPISODE:  335 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 4\n",
            "EPISODE:  336 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 3\n",
            "EPISODE:  337 \tREWARD:  -178.0 \tEPISODE_LENGTH:  178\n",
            "(18, 13) 2\n",
            "EPISODE:  338 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 4\n",
            "EPISODE:  339 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 5\n",
            "EPISODE:  340 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 13) 3\n",
            "EPISODE:  341 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 1\n",
            "EPISODE:  342 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 2\n",
            "EPISODE:  343 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 3\n",
            "EPISODE:  344 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 13) 7\n",
            "EPISODE:  345 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 3\n",
            "EPISODE:  346 \tREWARD:  -175.0 \tEPISODE_LENGTH:  175\n",
            "(18, 12) 3\n",
            "EPISODE:  347 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 7\n",
            "EPISODE:  348 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 12) 5\n",
            "EPISODE:  349 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 4\n",
            "EPISODE:  350 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 4\n",
            "EPISODE:  351 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 3\n",
            "EPISODE:  352 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 2\n",
            "EPISODE:  353 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  354 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 5\n",
            "EPISODE:  355 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 8\n",
            "EPISODE:  356 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 12) 3\n",
            "EPISODE:  357 \tREWARD:  -175.0 \tEPISODE_LENGTH:  175\n",
            "(18, 12) 5\n",
            "EPISODE:  358 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 13) 2\n",
            "EPISODE:  359 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 11) 4\n",
            "EPISODE:  360 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 1\n",
            "EPISODE:  361 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 4\n",
            "EPISODE:  362 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 2\n",
            "EPISODE:  363 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 2\n",
            "EPISODE:  364 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 3\n",
            "EPISODE:  365 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 11) 7\n",
            "EPISODE:  366 \tREWARD:  -179.0 \tEPISODE_LENGTH:  179\n",
            "(18, 13) 7\n",
            "EPISODE:  367 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 3\n",
            "EPISODE:  368 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 5\n",
            "EPISODE:  369 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 1\n",
            "EPISODE:  370 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 4\n",
            "EPISODE:  371 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 1\n",
            "EPISODE:  372 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 4\n",
            "EPISODE:  373 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 5\n",
            "EPISODE:  374 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  375 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 7\n",
            "EPISODE:  376 \tREWARD:  -262.0 \tEPISODE_LENGTH:  262\n",
            "(18, 13) 2\n",
            "EPISODE:  377 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 3\n",
            "EPISODE:  378 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 1\n",
            "EPISODE:  379 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 11) 5\n",
            "EPISODE:  380 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 13) 4\n",
            "EPISODE:  381 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 1\n",
            "EPISODE:  382 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 7\n",
            "EPISODE:  383 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 6\n",
            "EPISODE:  384 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 2\n",
            "EPISODE:  385 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  386 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 2\n",
            "EPISODE:  387 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 7\n",
            "EPISODE:  388 \tREWARD:  -180.0 \tEPISODE_LENGTH:  180\n",
            "(18, 13) 6\n",
            "EPISODE:  389 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 4\n",
            "EPISODE:  390 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 12) 2\n",
            "EPISODE:  391 \tREWARD:  -179.0 \tEPISODE_LENGTH:  179\n",
            "(18, 13) 3\n",
            "EPISODE:  392 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 1\n",
            "EPISODE:  393 \tREWARD:  -178.0 \tEPISODE_LENGTH:  178\n",
            "(18, 13) 5\n",
            "EPISODE:  394 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 3\n",
            "EPISODE:  395 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 13) 2\n",
            "EPISODE:  396 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 2\n",
            "EPISODE:  397 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 5\n",
            "EPISODE:  398 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 2\n",
            "EPISODE:  399 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 3\n",
            "EPISODE:  400 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 12) 3\n",
            "EPISODE:  401 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 12) 4\n",
            "EPISODE:  402 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 1\n",
            "EPISODE:  403 \tREWARD:  -187.0 \tEPISODE_LENGTH:  187\n",
            "(18, 13) 1\n",
            "EPISODE:  404 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 3\n",
            "EPISODE:  405 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 1\n",
            "EPISODE:  406 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  407 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 2\n",
            "EPISODE:  408 \tREWARD:  -175.0 \tEPISODE_LENGTH:  175\n",
            "(18, 12) 1\n",
            "EPISODE:  409 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 1\n",
            "EPISODE:  410 \tREWARD:  -173.0 \tEPISODE_LENGTH:  173\n",
            "(18, 13) 1\n",
            "EPISODE:  411 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 0\n",
            "EPISODE:  412 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  413 \tREWARD:  -175.0 \tEPISODE_LENGTH:  175\n",
            "(18, 13) 1\n",
            "EPISODE:  414 \tREWARD:  -178.0 \tEPISODE_LENGTH:  178\n",
            "(18, 13) 2\n",
            "EPISODE:  415 \tREWARD:  -181.0 \tEPISODE_LENGTH:  181\n",
            "(18, 13) 3\n",
            "EPISODE:  416 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 13) 0\n",
            "EPISODE:  417 \tREWARD:  -173.0 \tEPISODE_LENGTH:  173\n",
            "(18, 13) 3\n",
            "EPISODE:  418 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 13) 2\n",
            "EPISODE:  419 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 1\n",
            "EPISODE:  420 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 3\n",
            "EPISODE:  421 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 1\n",
            "EPISODE:  422 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 1\n",
            "EPISODE:  423 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 4\n",
            "EPISODE:  424 \tREWARD:  -181.0 \tEPISODE_LENGTH:  181\n",
            "(18, 13) 1\n",
            "EPISODE:  425 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 11) 3\n",
            "EPISODE:  426 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  427 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 11) 3\n",
            "EPISODE:  428 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 13) 0\n",
            "EPISODE:  429 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 12) 3\n",
            "EPISODE:  430 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 2\n",
            "EPISODE:  431 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 1\n",
            "EPISODE:  432 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 12) 1\n",
            "EPISODE:  433 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 2\n",
            "EPISODE:  434 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 3\n",
            "EPISODE:  435 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 3\n",
            "EPISODE:  436 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 1\n",
            "EPISODE:  437 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 3\n",
            "EPISODE:  438 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 1\n",
            "EPISODE:  439 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 2\n",
            "EPISODE:  440 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 1\n",
            "EPISODE:  441 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 4\n",
            "EPISODE:  442 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 1\n",
            "EPISODE:  443 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  444 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 13) 1\n",
            "EPISODE:  445 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 12) 1\n",
            "EPISODE:  446 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 1\n",
            "EPISODE:  447 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 0\n",
            "EPISODE:  448 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 1\n",
            "EPISODE:  449 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  450 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  451 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 3\n",
            "EPISODE:  452 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  453 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 1\n",
            "EPISODE:  454 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 1\n",
            "EPISODE:  455 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 4\n",
            "EPISODE:  456 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 12) 1\n",
            "EPISODE:  457 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 1\n",
            "EPISODE:  458 \tREWARD:  -247.0 \tEPISODE_LENGTH:  247\n",
            "(18, 13) 1\n",
            "EPISODE:  459 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 2\n",
            "EPISODE:  460 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 2\n",
            "EPISODE:  461 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 13) 2\n",
            "EPISODE:  462 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 1\n",
            "EPISODE:  463 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 13) 0\n",
            "EPISODE:  464 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 1\n",
            "EPISODE:  465 \tREWARD:  -180.0 \tEPISODE_LENGTH:  180\n",
            "(18, 13) 2\n",
            "EPISODE:  466 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 3\n",
            "EPISODE:  467 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 1\n",
            "EPISODE:  468 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 2\n",
            "EPISODE:  469 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 12) 2\n",
            "EPISODE:  470 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 13) 2\n",
            "EPISODE:  471 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  472 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 2\n",
            "EPISODE:  473 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 12) 3\n",
            "EPISODE:  474 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 2\n",
            "EPISODE:  475 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  476 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 3\n",
            "EPISODE:  477 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 2\n",
            "EPISODE:  478 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  479 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 1\n",
            "EPISODE:  480 \tREWARD:  -163.0 \tEPISODE_LENGTH:  163\n",
            "(18, 13) 3\n",
            "EPISODE:  481 \tREWARD:  -245.0 \tEPISODE_LENGTH:  245\n",
            "(18, 13) 1\n",
            "EPISODE:  482 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 2\n",
            "EPISODE:  483 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 1\n",
            "EPISODE:  484 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 1\n",
            "EPISODE:  485 \tREWARD:  -258.0 \tEPISODE_LENGTH:  258\n",
            "(18, 13) 0\n",
            "EPISODE:  486 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  487 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  488 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  489 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 3\n",
            "EPISODE:  490 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  491 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 13) 2\n",
            "EPISODE:  492 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 2\n",
            "EPISODE:  493 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  494 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  495 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 3\n",
            "EPISODE:  496 \tREWARD:  -182.0 \tEPISODE_LENGTH:  182\n",
            "(18, 13) 0\n",
            "EPISODE:  497 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 2\n",
            "EPISODE:  498 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 0\n",
            "EPISODE:  499 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 13) 2\n",
            "EPISODE:  500 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 2\n",
            "EPISODE:  501 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 13) 0\n",
            "EPISODE:  502 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  503 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 1\n",
            "EPISODE:  504 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 12) 1\n",
            "EPISODE:  505 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 13) 0\n",
            "EPISODE:  506 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  507 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 1\n",
            "EPISODE:  508 \tREWARD:  -250.0 \tEPISODE_LENGTH:  250\n",
            "(18, 11) 1\n",
            "EPISODE:  509 \tREWARD:  -197.0 \tEPISODE_LENGTH:  197\n",
            "(18, 13) 1\n",
            "EPISODE:  510 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 2\n",
            "EPISODE:  511 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 13) 1\n",
            "EPISODE:  512 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 13) 1\n",
            "EPISODE:  513 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  514 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 1\n",
            "EPISODE:  515 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 1\n",
            "EPISODE:  516 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 3\n",
            "EPISODE:  517 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 1\n",
            "EPISODE:  518 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  519 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  520 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 2\n",
            "EPISODE:  521 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 0\n",
            "EPISODE:  522 \tREWARD:  -190.0 \tEPISODE_LENGTH:  190\n",
            "(18, 13) 2\n",
            "EPISODE:  523 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 0\n",
            "EPISODE:  524 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  525 \tREWARD:  -246.0 \tEPISODE_LENGTH:  246\n",
            "(18, 12) 0\n",
            "EPISODE:  526 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 1\n",
            "EPISODE:  527 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 2\n",
            "EPISODE:  528 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 2\n",
            "EPISODE:  529 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 2\n",
            "EPISODE:  530 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  531 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 13) 0\n",
            "EPISODE:  532 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  533 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 1\n",
            "EPISODE:  534 \tREWARD:  -177.0 \tEPISODE_LENGTH:  177\n",
            "(18, 13) 2\n",
            "EPISODE:  535 \tREWARD:  -255.0 \tEPISODE_LENGTH:  255\n",
            "(18, 13) 2\n",
            "EPISODE:  536 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 2\n",
            "EPISODE:  537 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 1\n",
            "EPISODE:  538 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 2\n",
            "EPISODE:  539 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  540 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 1\n",
            "EPISODE:  541 \tREWARD:  -245.0 \tEPISODE_LENGTH:  245\n",
            "(18, 13) 1\n",
            "EPISODE:  542 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 1\n",
            "EPISODE:  543 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 1\n",
            "EPISODE:  544 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  545 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  546 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 0\n",
            "EPISODE:  547 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  548 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  549 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 2\n",
            "EPISODE:  550 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  551 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 1\n",
            "EPISODE:  552 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 0\n",
            "EPISODE:  553 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 1\n",
            "EPISODE:  554 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 1\n",
            "EPISODE:  555 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  556 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 11) 0\n",
            "EPISODE:  557 \tREWARD:  -182.0 \tEPISODE_LENGTH:  182\n",
            "(18, 13) 1\n",
            "EPISODE:  558 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  559 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 1\n",
            "EPISODE:  560 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 1\n",
            "EPISODE:  561 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 1\n",
            "EPISODE:  562 \tREWARD:  -248.0 \tEPISODE_LENGTH:  248\n",
            "(18, 13) 0\n",
            "EPISODE:  563 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  564 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  565 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  566 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 1\n",
            "EPISODE:  567 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  568 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 3\n",
            "EPISODE:  569 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  570 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  571 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 0\n",
            "EPISODE:  572 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 0\n",
            "EPISODE:  573 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 0\n",
            "EPISODE:  574 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  575 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  576 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  577 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 1\n",
            "EPISODE:  578 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 1\n",
            "EPISODE:  579 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 1\n",
            "EPISODE:  580 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  581 \tREWARD:  -250.0 \tEPISODE_LENGTH:  250\n",
            "(18, 12) 1\n",
            "EPISODE:  582 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  583 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 1\n",
            "EPISODE:  584 \tREWARD:  -193.0 \tEPISODE_LENGTH:  193\n",
            "(18, 13) 1\n",
            "EPISODE:  585 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 3\n",
            "EPISODE:  586 \tREWARD:  -181.0 \tEPISODE_LENGTH:  181\n",
            "(18, 13) 0\n",
            "EPISODE:  587 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 11) 1\n",
            "EPISODE:  588 \tREWARD:  -213.0 \tEPISODE_LENGTH:  213\n",
            "(18, 13) 0\n",
            "EPISODE:  589 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 0\n",
            "EPISODE:  590 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  591 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  592 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  593 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  594 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  595 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  596 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  597 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 1\n",
            "EPISODE:  598 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  599 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 1\n",
            "EPISODE:  600 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 12) 1\n",
            "EPISODE:  601 \tREWARD:  -256.0 \tEPISODE_LENGTH:  256\n",
            "(18, 13) 1\n",
            "EPISODE:  602 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  603 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  604 \tREWARD:  -247.0 \tEPISODE_LENGTH:  247\n",
            "(18, 13) 1\n",
            "EPISODE:  605 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  606 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  607 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  608 \tREWARD:  -259.0 \tEPISODE_LENGTH:  259\n",
            "(18, 13) 0\n",
            "EPISODE:  609 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 1\n",
            "EPISODE:  610 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 0\n",
            "EPISODE:  611 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  612 \tREWARD:  -174.0 \tEPISODE_LENGTH:  174\n",
            "(18, 13) 0\n",
            "EPISODE:  613 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  614 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 0\n",
            "EPISODE:  615 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 0\n",
            "EPISODE:  616 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 1\n",
            "EPISODE:  617 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  618 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  619 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  620 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 1\n",
            "EPISODE:  621 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  622 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  623 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 1\n",
            "EPISODE:  624 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  625 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  626 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  627 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  628 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  629 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 1\n",
            "EPISODE:  630 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 0\n",
            "EPISODE:  631 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 1\n",
            "EPISODE:  632 \tREWARD:  -179.0 \tEPISODE_LENGTH:  179\n",
            "(18, 13) 0\n",
            "EPISODE:  633 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  634 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  635 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  636 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  637 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 1\n",
            "EPISODE:  638 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 0\n",
            "EPISODE:  639 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  640 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 1\n",
            "EPISODE:  641 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 1\n",
            "EPISODE:  642 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  643 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  644 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 1\n",
            "EPISODE:  645 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  646 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 13) 0\n",
            "EPISODE:  647 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  648 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  649 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  650 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 0\n",
            "EPISODE:  651 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 0\n",
            "EPISODE:  652 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 1\n",
            "EPISODE:  653 \tREWARD:  -184.0 \tEPISODE_LENGTH:  184\n",
            "(18, 13) 0\n",
            "EPISODE:  654 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 0\n",
            "EPISODE:  655 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  656 \tREWARD:  -247.0 \tEPISODE_LENGTH:  247\n",
            "(18, 13) 0\n",
            "EPISODE:  657 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  658 \tREWARD:  -248.0 \tEPISODE_LENGTH:  248\n",
            "(18, 13) 0\n",
            "EPISODE:  659 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  660 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  661 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  662 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  663 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 0\n",
            "EPISODE:  664 \tREWARD:  -181.0 \tEPISODE_LENGTH:  181\n",
            "(18, 13) 0\n",
            "EPISODE:  665 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  666 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  667 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  668 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  669 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  670 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  671 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  672 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  673 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 1\n",
            "EPISODE:  674 \tREWARD:  -248.0 \tEPISODE_LENGTH:  248\n",
            "(18, 13) 0\n",
            "EPISODE:  675 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  676 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 0\n",
            "EPISODE:  677 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  678 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  679 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 0\n",
            "EPISODE:  680 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  681 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  682 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  683 \tREWARD:  -247.0 \tEPISODE_LENGTH:  247\n",
            "(18, 13) 0\n",
            "EPISODE:  684 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  685 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 0\n",
            "EPISODE:  686 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  687 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  688 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  689 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  690 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 0\n",
            "EPISODE:  691 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 1\n",
            "EPISODE:  692 \tREWARD:  -246.0 \tEPISODE_LENGTH:  246\n",
            "(18, 13) 0\n",
            "EPISODE:  693 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  694 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  695 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  696 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  697 \tREWARD:  -258.0 \tEPISODE_LENGTH:  258\n",
            "(18, 13) 0\n",
            "EPISODE:  698 \tREWARD:  -247.0 \tEPISODE_LENGTH:  247\n",
            "(18, 13) 0\n",
            "EPISODE:  699 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  700 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  701 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  702 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 0\n",
            "EPISODE:  703 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 0\n",
            "EPISODE:  704 \tREWARD:  -257.0 \tEPISODE_LENGTH:  257\n",
            "(18, 13) 0\n",
            "EPISODE:  705 \tREWARD:  -179.0 \tEPISODE_LENGTH:  179\n",
            "(18, 13) 0\n",
            "EPISODE:  706 \tREWARD:  -265.0 \tEPISODE_LENGTH:  265\n",
            "(18, 12) 1\n",
            "EPISODE:  707 \tREWARD:  -179.0 \tEPISODE_LENGTH:  179\n",
            "(18, 13) 0\n",
            "EPISODE:  708 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 0\n",
            "EPISODE:  709 \tREWARD:  -257.0 \tEPISODE_LENGTH:  257\n",
            "(18, 13) 0\n",
            "EPISODE:  710 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 0\n",
            "EPISODE:  711 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 0\n",
            "EPISODE:  712 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  713 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  714 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 1\n",
            "EPISODE:  715 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 0\n",
            "EPISODE:  716 \tREWARD:  -195.0 \tEPISODE_LENGTH:  195\n",
            "(18, 13) 0\n",
            "EPISODE:  717 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  718 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  719 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 0\n",
            "EPISODE:  720 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  721 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  722 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  723 \tREWARD:  -247.0 \tEPISODE_LENGTH:  247\n",
            "(18, 13) 1\n",
            "EPISODE:  724 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  725 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  726 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  727 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  728 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  729 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  730 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 0\n",
            "EPISODE:  731 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  732 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  733 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 11) 1\n",
            "EPISODE:  734 \tREWARD:  -195.0 \tEPISODE_LENGTH:  195\n",
            "(18, 13) 0\n",
            "EPISODE:  735 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  736 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 0\n",
            "EPISODE:  737 \tREWARD:  -184.0 \tEPISODE_LENGTH:  184\n",
            "(18, 13) 0\n",
            "EPISODE:  738 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  739 \tREWARD:  -250.0 \tEPISODE_LENGTH:  250\n",
            "(18, 13) 0\n",
            "EPISODE:  740 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 1\n",
            "EPISODE:  741 \tREWARD:  -247.0 \tEPISODE_LENGTH:  247\n",
            "(18, 13) 0\n",
            "EPISODE:  742 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  743 \tREWARD:  -259.0 \tEPISODE_LENGTH:  259\n",
            "(18, 13) 0\n",
            "EPISODE:  744 \tREWARD:  -255.0 \tEPISODE_LENGTH:  255\n",
            "(18, 13) 0\n",
            "EPISODE:  745 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  746 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 0\n",
            "EPISODE:  747 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  748 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  749 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  750 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  751 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  752 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  753 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  754 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  755 \tREWARD:  -176.0 \tEPISODE_LENGTH:  176\n",
            "(18, 13) 0\n",
            "EPISODE:  756 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  757 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  758 \tREWARD:  -248.0 \tEPISODE_LENGTH:  248\n",
            "(18, 13) 0\n",
            "EPISODE:  759 \tREWARD:  -183.0 \tEPISODE_LENGTH:  183\n",
            "(18, 13) 0\n",
            "EPISODE:  760 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  761 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  762 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  763 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  764 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  765 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  766 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  767 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  768 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  769 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  770 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  771 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 11) 0\n",
            "EPISODE:  772 \tREWARD:  -202.0 \tEPISODE_LENGTH:  202\n",
            "(18, 13) 0\n",
            "EPISODE:  773 \tREWARD:  -273.0 \tEPISODE_LENGTH:  273\n",
            "(18, 13) 0\n",
            "EPISODE:  774 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 13) 0\n",
            "EPISODE:  775 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  776 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  777 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  778 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  779 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  780 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  781 \tREWARD:  -258.0 \tEPISODE_LENGTH:  258\n",
            "(18, 13) 0\n",
            "EPISODE:  782 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  783 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  784 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  785 \tREWARD:  -274.0 \tEPISODE_LENGTH:  274\n",
            "(18, 13) 0\n",
            "EPISODE:  786 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 13) 0\n",
            "EPISODE:  787 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  788 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 0\n",
            "EPISODE:  789 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 1\n",
            "EPISODE:  790 \tREWARD:  -250.0 \tEPISODE_LENGTH:  250\n",
            "(18, 13) 0\n",
            "EPISODE:  791 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  792 \tREWARD:  -181.0 \tEPISODE_LENGTH:  181\n",
            "(18, 13) 0\n",
            "EPISODE:  793 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  794 \tREWARD:  -255.0 \tEPISODE_LENGTH:  255\n",
            "(18, 13) 0\n",
            "EPISODE:  795 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  796 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  797 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  798 \tREWARD:  -267.0 \tEPISODE_LENGTH:  267\n",
            "(18, 12) 0\n",
            "EPISODE:  799 \tREWARD:  -184.0 \tEPISODE_LENGTH:  184\n",
            "(18, 13) 0\n",
            "EPISODE:  800 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 0\n",
            "EPISODE:  801 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 12) 0\n",
            "EPISODE:  802 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  803 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  804 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  805 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  806 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 1\n",
            "EPISODE:  807 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 12) 0\n",
            "EPISODE:  808 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  809 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  810 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  811 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  812 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  813 \tREWARD:  -178.0 \tEPISODE_LENGTH:  178\n",
            "(18, 13) 0\n",
            "EPISODE:  814 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  815 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 0\n",
            "EPISODE:  816 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 1\n",
            "EPISODE:  817 \tREWARD:  -269.0 \tEPISODE_LENGTH:  269\n",
            "(18, 13) 0\n",
            "EPISODE:  818 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  819 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  820 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  821 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  822 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 0\n",
            "EPISODE:  823 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  824 \tREWARD:  -263.0 \tEPISODE_LENGTH:  263\n",
            "(18, 12) 0\n",
            "EPISODE:  825 \tREWARD:  -179.0 \tEPISODE_LENGTH:  179\n",
            "(18, 13) 0\n",
            "EPISODE:  826 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 0\n",
            "EPISODE:  827 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 13) 0\n",
            "EPISODE:  828 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  829 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  830 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 0\n",
            "EPISODE:  831 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  832 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 0\n",
            "EPISODE:  833 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  834 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  835 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  836 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  837 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  838 \tREWARD:  -246.0 \tEPISODE_LENGTH:  246\n",
            "(18, 13) 0\n",
            "EPISODE:  839 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 0\n",
            "EPISODE:  840 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  841 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 1\n",
            "EPISODE:  842 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 0\n",
            "EPISODE:  843 \tREWARD:  -250.0 \tEPISODE_LENGTH:  250\n",
            "(18, 13) 0\n",
            "EPISODE:  844 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  845 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  846 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  847 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  848 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  849 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 0\n",
            "EPISODE:  850 \tREWARD:  -163.0 \tEPISODE_LENGTH:  163\n",
            "(18, 13) 0\n",
            "EPISODE:  851 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  852 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  853 \tREWARD:  -245.0 \tEPISODE_LENGTH:  245\n",
            "(18, 13) 0\n",
            "EPISODE:  854 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  855 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  856 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  857 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 0\n",
            "EPISODE:  858 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  859 \tREWARD:  -260.0 \tEPISODE_LENGTH:  260\n",
            "(18, 13) 0\n",
            "EPISODE:  860 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  861 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  862 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  863 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 13) 0\n",
            "EPISODE:  864 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  865 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  866 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  867 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 0\n",
            "EPISODE:  868 \tREWARD:  -264.0 \tEPISODE_LENGTH:  264\n",
            "(18, 13) 0\n",
            "EPISODE:  869 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  870 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 12) 1\n",
            "EPISODE:  871 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  872 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 0\n",
            "EPISODE:  873 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  874 \tREWARD:  -178.0 \tEPISODE_LENGTH:  178\n",
            "(18, 13) 0\n",
            "EPISODE:  875 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  876 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  877 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 0\n",
            "EPISODE:  878 \tREWARD:  -172.0 \tEPISODE_LENGTH:  172\n",
            "(18, 13) 0\n",
            "EPISODE:  879 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  880 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  881 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  882 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 0\n",
            "EPISODE:  883 \tREWARD:  -163.0 \tEPISODE_LENGTH:  163\n",
            "(18, 13) 0\n",
            "EPISODE:  884 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  885 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  886 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  887 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  888 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  889 \tREWARD:  -269.0 \tEPISODE_LENGTH:  269\n",
            "(18, 13) 0\n",
            "EPISODE:  890 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  891 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  892 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  893 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  894 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  895 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 12) 0\n",
            "EPISODE:  896 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  897 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  898 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  899 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  900 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  901 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  902 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  903 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 12) 0\n",
            "EPISODE:  904 \tREWARD:  -261.0 \tEPISODE_LENGTH:  261\n",
            "(18, 13) 0\n",
            "EPISODE:  905 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  906 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  907 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 0\n",
            "EPISODE:  908 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  909 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 0\n",
            "EPISODE:  910 \tREWARD:  -270.0 \tEPISODE_LENGTH:  270\n",
            "(18, 13) 0\n",
            "EPISODE:  911 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  912 \tREWARD:  -250.0 \tEPISODE_LENGTH:  250\n",
            "(18, 13) 0\n",
            "EPISODE:  913 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  914 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 0\n",
            "EPISODE:  915 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  916 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  917 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  918 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  919 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  920 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  921 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  922 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  923 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  924 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  925 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  926 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  927 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  928 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 0\n",
            "EPISODE:  929 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  930 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 13) 0\n",
            "EPISODE:  931 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  932 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 0\n",
            "EPISODE:  933 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  934 \tREWARD:  -250.0 \tEPISODE_LENGTH:  250\n",
            "(18, 13) 0\n",
            "EPISODE:  935 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  936 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  937 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 0\n",
            "EPISODE:  938 \tREWARD:  -187.0 \tEPISODE_LENGTH:  187\n",
            "(18, 13) 0\n",
            "EPISODE:  939 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  940 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  941 \tREWARD:  -192.0 \tEPISODE_LENGTH:  192\n",
            "(18, 13) 0\n",
            "EPISODE:  942 \tREWARD:  -177.0 \tEPISODE_LENGTH:  177\n",
            "(18, 13) 0\n",
            "EPISODE:  943 \tREWARD:  -270.0 \tEPISODE_LENGTH:  270\n",
            "(18, 13) 0\n",
            "EPISODE:  944 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 12) 0\n",
            "EPISODE:  945 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  946 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  947 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  948 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  949 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  950 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  951 \tREWARD:  -254.0 \tEPISODE_LENGTH:  254\n",
            "(18, 13) 0\n",
            "EPISODE:  952 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  953 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 0\n",
            "EPISODE:  954 \tREWARD:  -177.0 \tEPISODE_LENGTH:  177\n",
            "(18, 13) 0\n",
            "EPISODE:  955 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 0\n",
            "EPISODE:  956 \tREWARD:  -171.0 \tEPISODE_LENGTH:  171\n",
            "(18, 13) 0\n",
            "EPISODE:  957 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  958 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  959 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  960 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  961 \tREWARD:  -182.0 \tEPISODE_LENGTH:  182\n",
            "(18, 13) 0\n",
            "EPISODE:  962 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  963 \tREWARD:  -200.0 \tEPISODE_LENGTH:  200\n",
            "(18, 13) 0\n",
            "EPISODE:  964 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  965 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  966 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  967 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  968 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  969 \tREWARD:  -249.0 \tEPISODE_LENGTH:  249\n",
            "(18, 13) 0\n",
            "EPISODE:  970 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  971 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  972 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 0\n",
            "EPISODE:  973 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  974 \tREWARD:  -163.0 \tEPISODE_LENGTH:  163\n",
            "(18, 13) 0\n",
            "EPISODE:  975 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  976 \tREWARD:  -253.0 \tEPISODE_LENGTH:  253\n",
            "(18, 13) 0\n",
            "EPISODE:  977 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  978 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  979 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  980 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  981 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  982 \tREWARD:  -169.0 \tEPISODE_LENGTH:  169\n",
            "(18, 13) 0\n",
            "EPISODE:  983 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  984 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  985 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  986 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  987 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  988 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  989 \tREWARD:  -256.0 \tEPISODE_LENGTH:  256\n",
            "(18, 13) 0\n",
            "EPISODE:  990 \tREWARD:  -168.0 \tEPISODE_LENGTH:  168\n",
            "(18, 13) 0\n",
            "EPISODE:  991 \tREWARD:  -196.0 \tEPISODE_LENGTH:  196\n",
            "(18, 13) 0\n",
            "EPISODE:  992 \tREWARD:  -170.0 \tEPISODE_LENGTH:  170\n",
            "(18, 13) 0\n",
            "EPISODE:  993 \tREWARD:  -258.0 \tEPISODE_LENGTH:  258\n",
            "(18, 13) 0\n",
            "EPISODE:  994 \tREWARD:  -165.0 \tEPISODE_LENGTH:  165\n",
            "(18, 13) 0\n",
            "EPISODE:  995 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n",
            "(18, 13) 0\n",
            "EPISODE:  996 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 13) 0\n",
            "EPISODE:  997 \tREWARD:  -164.0 \tEPISODE_LENGTH:  164\n",
            "(18, 13) 0\n",
            "EPISODE:  998 \tREWARD:  -167.0 \tEPISODE_LENGTH:  167\n",
            "(18, 13) 0\n",
            "EPISODE:  999 \tREWARD:  -252.0 \tEPISODE_LENGTH:  252\n",
            "(18, 13) 0\n",
            "EPISODE:  1000 \tREWARD:  -166.0 \tEPISODE_LENGTH:  166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1VT6KbJ2hap"
      },
      "source": [
        "# **Playing with the Environment**\n",
        "\n",
        "#### **Instantiating the environment** :\n",
        "You can create an environment by calling the following function:  \n",
        "`environments.load_env(ENV_ID)` - RETURNS: `env`  \n",
        "where, ENV_ID can be ONE of the following:\n",
        "* `environments.CATCH`\n",
        "* `environments.CATCH_NOISE`\n",
        "* `environments.CARTPOLE`\n",
        "* `environments.CARTPOLE_NOISE`\n",
        "* `environments.MOUNTAINCAR`\n",
        "* `environments.MOUNTAINCAR_NOISE`\n",
        "\n",
        "The `NOISE` environments add a scaled random noise to the `reward`.\n",
        "<br/>\n",
        "\n",
        "#### **Runnning the environment** :\n",
        "There are certain methods required to run the environments. The interface is very similar to OpenAI Gym's interfaces. Fore more information, read the OpenAI documentation [here](https://gym.openai.com/docs/).\n",
        "\n",
        "`env.reset()` - RETURNS: `observation`  \n",
        "`env.step(action)`  - RETURNS: `(next_observation, reward, done, info[NOT USED])`\n",
        "\n",
        "There are also a few useful properties within the environments:\n",
        "\n",
        "* `env.action_space.n` - total number of possible actions. eg: if 'n' is 3, then the possible actions are `[0, 1, 2]`\n",
        "* `env.observation_space.shape` -  the shape of the observation.\n",
        "* `env.bsuite_num_episodes` -  the pre-specified number of episodes which will be run during evaluation (unique for each environment).\n",
        "\n",
        "##### *ONLY IN CATCH / CATCH_NOISE*\n",
        "* `env.observation_space.high` -  the upper limit for every index in the observation.\n",
        "* `env.observation_space.low` -  the lower limit for every index of the observation.\n",
        "<br/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Rn-yoU5I7o"
      },
      "source": [
        "## **Environment Observation Space Limits:**\n",
        "\n",
        "The limits for the observation space (minimum and maximum) for all the environments are given in the table below:\n",
        "\n",
        "| Environments                        | Limits                                                                      |\n",
        "|-------------------------------------|-----------------------------------------------------------------------------|\n",
        "| CATCH <br/>  CATCH_NOISE            | MIN: use `env.observation_space.low` <br/> MAX: use `env.observation_space.high` |\n",
        "| CARTPOLE <br/> CARTPOLE_NOISE       | MIN: `[-1. -5., -1., -1., -5., 0.]` <br/> MAX: `[ 1.,  5.,  1.,  1.,  5., 1.]` |\n",
        "| MOUNTAINCAR <br/> MOUNTAINCAR_NOISE | MIN: `[-1.2, -0.07, 0.]` <br/> MAX: `[ 0.6,  0.07,  1.]`                                 |\n",
        "\n",
        "[NOTE] Use this code cell to play around and get used to the environments. However, the `Runner` class below will be used to evaluate your agent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvfNKtUOJ2ho",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fb43897e20584d6a9d033c3b1cdef501",
            "8e615bbf425a4021a800758f7245c097",
            "dbeff19a5ab84363afff6a6dfcdffb7e",
            "e9af7a567af046d8bdac3fbbc1130ca6",
            "ba7ae004ef1d41f698eccce6a58847d8",
            "25c94db0b356475cabfe49468ae4aa82",
            "63b547ffe8404d5e9c96684194022269",
            "c40c33c13d8c47d3be0aff3e1561a2ea",
            "294ddce7b6bd4baaa13249d16e8e3417",
            "53694f710c2f44c99f4e1b75c3b940e7",
            "a7e5f4856801480cbe6f07556418b6aa"
          ]
        },
        "outputId": "be533f20-4f54-4e0c-b07e-9edfe0ddf7a1"
      },
      "source": [
        "# *** YOU CAN EDIT THIS CELL ***\n",
        "# TEST AREA\n",
        "env = environments.load_env(environments.MOUNTAINCAR)  # replace 'environments.CARTPOLE' with other environments\n",
        "\n",
        "agent = Agent47(agent_config={\"env_name\": 'mountaincar'})    # replace with 'RandomAgent()' to use your custom agent\n",
        "\n",
        "NUM_EPISODES = 100                                   # replace with 'env.bsuite_num_episodes' to run for pre-specified number of episodes\n",
        "for episode_n in tqdm(range(NUM_EPISODES)):\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "    episode_moves = 0\n",
        " \n",
        "    observation = env.reset()\n",
        "    state = agent.get_state(observation)\n",
        "\n",
        "    while not done:\n",
        "        action = agent.get_action(state)\n",
        "        next_observation, reward, done, _ = env.step(action)\n",
        "        next_state = agent.get_state(next_observation)\n",
        "\n",
        "        agent.learn(state, action, reward, next_state, done)\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "        episode_reward += reward\n",
        "        episode_moves += 1\n",
        "\n",
        "    if (((episode_n+1) % 2) == 0): \n",
        "        print(\"EPISODE: \",episode_n+1,\"\\tREWARD: \",episode_reward,\"\\tEPISODE_LENGTH: \",episode_moves)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[37mLoaded bsuite_id: mountain_car/0.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb43897e20584d6a9d033c3b1cdef501",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(7, 3) 790\n",
            "(11, 4) 799\n",
            "EPISODE:  2 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(13, 13) 789\n",
            "(2, 14) 779\n",
            "EPISODE:  4 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 12) 530\n",
            "(18, 11) 452\n",
            "EPISODE:  6 \tREWARD:  -615.0 \tEPISODE_LENGTH:  615\n",
            "(18, 11) 546\n",
            "(0, 11) 737\n",
            "EPISODE:  8 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(14, 7) 741\n",
            "(6, 17) 727\n",
            "EPISODE:  10 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 11) 588\n",
            "(18, 13) 643\n",
            "EPISODE:  12 \tREWARD:  -905.0 \tEPISODE_LENGTH:  905\n",
            "(15, 11) 714\n",
            "(18, 13) 462\n",
            "EPISODE:  14 \tREWARD:  -681.0 \tEPISODE_LENGTH:  681\n",
            "(18, 13) 686\n",
            "(11, 4) 687\n",
            "EPISODE:  16 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 11) 629\n",
            "(7, 0) 668\n",
            "EPISODE:  18 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 11) 346\n",
            "(4, 2) 677\n",
            "EPISODE:  20 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 11) 167\n",
            "(12, 4) 649\n",
            "EPISODE:  22 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(6, 16) 654\n",
            "(18, 12) 493\n",
            "EPISODE:  24 \tREWARD:  -784.0 \tEPISODE_LENGTH:  784\n",
            "(18, 11) 517\n",
            "(15, 11) 600\n",
            "EPISODE:  26 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 11) 515\n",
            "(18, 11) 571\n",
            "EPISODE:  28 \tREWARD:  -986.0 \tEPISODE_LENGTH:  986\n",
            "(18, 13) 573\n",
            "(18, 10) 560\n",
            "EPISODE:  30 \tREWARD:  -958.0 \tEPISODE_LENGTH:  958\n",
            "(18, 12) 440\n",
            "(10, 16) 591\n",
            "EPISODE:  32 \tREWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "(18, 11) 549\n",
            "(18, 11) 461\n",
            "EPISODE:  34 \tREWARD:  -806.0 \tEPISODE_LENGTH:  806\n",
            "(18, 11) 557\n",
            "(18, 12) 385\n",
            "EPISODE:  36 \tREWARD:  -691.0 \tEPISODE_LENGTH:  691\n",
            "(18, 11) 188\n",
            "(18, 11) 353\n",
            "EPISODE:  38 \tREWARD:  -646.0 \tEPISODE_LENGTH:  646\n",
            "(18, 12) 387\n",
            "(18, 11) 282\n",
            "EPISODE:  40 \tREWARD:  -474.0 \tEPISODE_LENGTH:  474\n",
            "(18, 13) 361\n",
            "(18, 11) 313\n",
            "EPISODE:  42 \tREWARD:  -600.0 \tEPISODE_LENGTH:  600\n",
            "(18, 13) 394\n",
            "(18, 10) 293\n",
            "EPISODE:  44 \tREWARD:  -554.0 \tEPISODE_LENGTH:  554\n",
            "(18, 11) 194\n",
            "(18, 13) 167\n",
            "EPISODE:  46 \tREWARD:  -327.0 \tEPISODE_LENGTH:  327\n",
            "(18, 11) 406\n",
            "(18, 12) 140\n",
            "EPISODE:  48 \tREWARD:  -275.0 \tEPISODE_LENGTH:  275\n",
            "(18, 12) 277\n",
            "(18, 12) 115\n",
            "EPISODE:  50 \tREWARD:  -258.0 \tEPISODE_LENGTH:  258\n",
            "(18, 12) 173\n",
            "(18, 12) 384\n",
            "EPISODE:  52 \tREWARD:  -755.0 \tEPISODE_LENGTH:  755\n",
            "(18, 11) 121\n",
            "(18, 12) 175\n",
            "EPISODE:  54 \tREWARD:  -398.0 \tEPISODE_LENGTH:  398\n",
            "(18, 12) 147\n",
            "(18, 12) 198\n",
            "EPISODE:  56 \tREWARD:  -433.0 \tEPISODE_LENGTH:  433\n",
            "(18, 11) 252\n",
            "(18, 11) 193\n",
            "EPISODE:  58 \tREWARD:  -437.0 \tEPISODE_LENGTH:  437\n",
            "(18, 11) 137\n",
            "(18, 12) 266\n",
            "EPISODE:  60 \tREWARD:  -617.0 \tEPISODE_LENGTH:  617\n",
            "(18, 11) 303\n",
            "(18, 12) 282\n",
            "EPISODE:  62 \tREWARD:  -681.0 \tEPISODE_LENGTH:  681\n",
            "(18, 12) 106\n",
            "(18, 11) 127\n",
            "EPISODE:  64 \tREWARD:  -306.0 \tEPISODE_LENGTH:  306\n",
            "(18, 12) 273\n",
            "(18, 11) 106\n",
            "EPISODE:  66 \tREWARD:  -268.0 \tEPISODE_LENGTH:  268\n",
            "(18, 13) 102\n",
            "(18, 12) 169\n",
            "EPISODE:  68 \tREWARD:  -465.0 \tEPISODE_LENGTH:  465\n",
            "(18, 12) 98\n",
            "(18, 12) 213\n",
            "EPISODE:  70 \tREWARD:  -497.0 \tEPISODE_LENGTH:  497\n",
            "(18, 12) 144\n",
            "(18, 11) 116\n",
            "EPISODE:  72 \tREWARD:  -251.0 \tEPISODE_LENGTH:  251\n",
            "(18, 11) 51\n",
            "(18, 11) 91\n",
            "EPISODE:  74 \tREWARD:  -255.0 \tEPISODE_LENGTH:  255\n",
            "(18, 13) 240\n",
            "(18, 11) 131\n",
            "EPISODE:  76 \tREWARD:  -339.0 \tEPISODE_LENGTH:  339\n",
            "(18, 11) 169\n",
            "(18, 12) 133\n",
            "EPISODE:  78 \tREWARD:  -366.0 \tEPISODE_LENGTH:  366\n",
            "(18, 11) 91\n",
            "(18, 12) 121\n",
            "EPISODE:  80 \tREWARD:  -331.0 \tEPISODE_LENGTH:  331\n",
            "(18, 11) 83\n",
            "(18, 11) 94\n",
            "EPISODE:  82 \tREWARD:  -257.0 \tEPISODE_LENGTH:  257\n",
            "(18, 12) 139\n",
            "(18, 10) 75\n",
            "EPISODE:  84 \tREWARD:  -191.0 \tEPISODE_LENGTH:  191\n",
            "(18, 12) 166\n",
            "(18, 11) 82\n",
            "EPISODE:  86 \tREWARD:  -275.0 \tEPISODE_LENGTH:  275\n",
            "(18, 14) 55\n",
            "(18, 12) 195\n",
            "EPISODE:  88 \tREWARD:  -625.0 \tEPISODE_LENGTH:  625\n",
            "(18, 11) 151\n",
            "(18, 14) 205\n",
            "EPISODE:  90 \tREWARD:  -637.0 \tEPISODE_LENGTH:  637\n",
            "(18, 11) 68\n",
            "(18, 11) 79\n",
            "EPISODE:  92 \tREWARD:  -268.0 \tEPISODE_LENGTH:  268\n",
            "(18, 12) 78\n",
            "(18, 11) 88\n",
            "EPISODE:  94 \tREWARD:  -268.0 \tEPISODE_LENGTH:  268\n",
            "(18, 12) 134\n",
            "(18, 13) 106\n",
            "EPISODE:  96 \tREWARD:  -330.0 \tEPISODE_LENGTH:  330\n",
            "(18, 13) 172\n",
            "(18, 11) 59\n",
            "EPISODE:  98 \tREWARD:  -214.0 \tEPISODE_LENGTH:  214\n",
            "(18, 11) 118\n",
            "(18, 13) 91\n",
            "EPISODE:  100 \tREWARD:  -292.0 \tEPISODE_LENGTH:  292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAvLTbG54kjm"
      },
      "source": [
        "## Point to the Agent Class you'll use for the final score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSoj2BqL4iih"
      },
      "source": [
        "RLAgent = Agent47"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HmaWuWSDhuX"
      },
      "source": [
        "# **Evaluating the Agent on all the Environments**\n",
        "\n",
        "* The following cells will take care of running your agent on each environment and aggregating the results in csv files. In each of the following cells, the `agent_config` parameter is already set to use the corresponding config dictionary for that environment. DO NOT EDIT THIS.\n",
        "* Feel free to modify the `LOG_INTERVAL` parameter to change the interval between episodes for logging.  \n",
        "* Please do not modify any other contents in each of the cells.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaVazKub5Ukk"
      },
      "source": [
        "LOG_INTERVAL = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wlYhvmvYjX5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406,
          "referenced_widgets": [
            "f5a039ff169841ec98809ea6139a1ce6",
            "176918e6913048a5b5094704342af225",
            "3ea9252df967459ca1cd70bf5a3b1919",
            "4971d15038bd4d7a97ddb2bc3305dfa1",
            "714fba70c9ac4910b34b0fb7b18554dd",
            "417f2db6f0b84f5c8d1ea7140b3b34d4",
            "5eab53c120234f4fb210e54d66db12f1",
            "db9f689cbae04a7a9ef4258c22f6d594",
            "2fc675cd97454bc18d4065fc50ea63f3",
            "1cf568dd4480407299ec8eb8f8442d83",
            "fe715cda8296412a82f10f2d096ae7a7"
          ]
        },
        "outputId": "18b19cf9-baa2-43c3-a47b-ea6f0cecb88a"
      },
      "source": [
        "runner = Runner(\n",
        "    agent = RLAgent(agent_config=catch_config),\n",
        "    env_id = environments.CATCH,\n",
        "    log_interval = LOG_INTERVAL,\n",
        ")\n",
        "runner.play_episodes()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[37mLoaded bsuite_id: catch/0.\u001b[0m\n",
            "\u001b[1m\u001b[33mLogging results to CSV file for each bsuite_id in results.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5a039ff169841ec98809ea6139a1ce6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-6f8835ecc412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlog_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLOG_INTERVAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_episodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bsuite/aicrowd/runner.py\u001b[0m in \u001b[0;36mplay_episodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mnext_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-60f9751cccd8>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# use exploration policy with some probablity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#print(state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MmxdqXxCNCO"
      },
      "source": [
        "runner = Runner(\n",
        "    agent = RLAgent(agent_config=catch_noise_config),\n",
        "    env_id = environments.CATCH_NOISE,\n",
        "    log_interval = LOG_INTERVAL\n",
        ")\n",
        "runner.play_episodes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2tC9ud4CbqV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253,
          "referenced_widgets": [
            "b90643be64ef463780000c110329138b",
            "ae9c1f6638954eca9b0d6d57c4599622",
            "05a4513d50414f78ab5d7590e69786e4",
            "f6660de9ad1942c3a88ef1a0afa18f37",
            "5b5020da4fdd4c4882342541c9481ed3",
            "6f7ab746656640c993410e97b55d1399",
            "f75445d8eb204152b19cf14961470c8e",
            "b8d5e6b2dc5345d6bcf7e3f6d9003d37",
            "4cbeb94c64f04b4ea049dd77156c0d03",
            "70b9a6746dd84eac9ebd24da2c6315a1",
            "44c7a32f217c440598578dde68d6ac69"
          ]
        },
        "outputId": "1af9cc94-1233-4dbb-b957-9724ff9c98a5"
      },
      "source": [
        "runner = Runner(\n",
        "    agent = RLAgent(agent_config=cartpole_config),\n",
        "    env_id = environments.CARTPOLE,\n",
        "    log_interval = LOG_INTERVAL\n",
        ")\n",
        "runner.play_episodes()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[37mLoaded bsuite_id: cartpole/0.\u001b[0m\n",
            "\u001b[1m\u001b[33mLogging results to CSV file for each bsuite_id in results.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b90643be64ef463780000c110329138b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "EPISODE:  100 \tREWARD:  97.0 \tMEAN_REWARD:  78.04 \tEPISODE_LENGTH:  98\n",
            "EPISODE:  200 \tREWARD:  125.0 \tMEAN_REWARD:  76.83 \tEPISODE_LENGTH:  126\n",
            "EPISODE:  300 \tREWARD:  122.0 \tMEAN_REWARD:  77.05 \tEPISODE_LENGTH:  123\n",
            "EPISODE:  400 \tREWARD:  74.0 \tMEAN_REWARD:  79.39 \tEPISODE_LENGTH:  75\n",
            "EPISODE:  500 \tREWARD:  59.0 \tMEAN_REWARD:  77.64 \tEPISODE_LENGTH:  60\n",
            "EPISODE:  600 \tREWARD:  61.0 \tMEAN_REWARD:  80.76 \tEPISODE_LENGTH:  62\n",
            "EPISODE:  700 \tREWARD:  118.0 \tMEAN_REWARD:  81.49 \tEPISODE_LENGTH:  119\n",
            "EPISODE:  800 \tREWARD:  71.0 \tMEAN_REWARD:  82.55 \tEPISODE_LENGTH:  72\n",
            "EPISODE:  900 \tREWARD:  115.0 \tMEAN_REWARD:  78.71 \tEPISODE_LENGTH:  116\n",
            "EPISODE:  1000 \tREWARD:  111.0 \tMEAN_REWARD:  81.57 \tEPISODE_LENGTH:  112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-H_Kym-CcCJ"
      },
      "source": [
        "runner = Runner(\n",
        "    agent = RLAgent(agent_config=cartpole_noise_config),\n",
        "    env_id = environments.CARTPOLE_NOISE,\n",
        "    log_interval = LOG_INTERVAL\n",
        ")\n",
        "runner.play_episodes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUSEPrdUCcEv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262,
          "referenced_widgets": [
            "ef650adaf9164a2cb58e3576b2042544",
            "1a2f24b55b584182a1c2dedb710c7c47",
            "1e7bdc3401ff405db7b0b246917a36bb",
            "69968349a1154b6a8044acea5ae35924",
            "570a444030ad4e4e874d929ae9d05fbd",
            "fcadc60ba4fb4bb58e07bd1aa121a680",
            "198644106e7c4108a12f0231ebb46e1e",
            "50cc7a2759444da8ae2aefc7bd97827a",
            "ba281706fd7c4629b86d985edcc13905",
            "2912e854ac2447f0b4625c35b9321bc6",
            "da84fa0b6c194b18a6e76a7d09bb8d5f"
          ]
        },
        "outputId": "e2388fd2-d3f3-465f-b46a-40c585b91feb"
      },
      "source": [
        "runner = Runner(\n",
        "    agent = RLAgent(agent_config=mountaincar_config),\n",
        "    env_id = environments.MOUNTAINCAR,\n",
        "    log_interval = LOG_INTERVAL\n",
        ")\n",
        "runner.play_episodes()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[37mLoaded bsuite_id: mountain_car/0.\u001b[0m\n",
            "\u001b[1m\u001b[33mLogging results to CSV file for each bsuite_id in results.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef650adaf9164a2cb58e3576b2042544",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "EPISODE:  100 \tREWARD:  -1000.0 \tMEAN_REWARD:  -1000.0 \tEPISODE_LENGTH:  1000\n",
            "EPISODE:  200 \tREWARD:  -403.0 \tMEAN_REWARD:  -698.94 \tEPISODE_LENGTH:  403\n",
            "EPISODE:  300 \tREWARD:  -540.0 \tMEAN_REWARD:  -468.92 \tEPISODE_LENGTH:  540\n",
            "EPISODE:  400 \tREWARD:  -282.0 \tMEAN_REWARD:  -382.08 \tEPISODE_LENGTH:  282\n",
            "EPISODE:  500 \tREWARD:  -209.0 \tMEAN_REWARD:  -373.31 \tEPISODE_LENGTH:  209\n",
            "EPISODE:  600 \tREWARD:  -1000.0 \tMEAN_REWARD:  -381.72 \tEPISODE_LENGTH:  1000\n",
            "EPISODE:  700 \tREWARD:  -917.0 \tMEAN_REWARD:  -358.57 \tEPISODE_LENGTH:  917\n",
            "EPISODE:  800 \tREWARD:  -534.0 \tMEAN_REWARD:  -366.58 \tEPISODE_LENGTH:  534\n",
            "EPISODE:  900 \tREWARD:  -517.0 \tMEAN_REWARD:  -378.38 \tEPISODE_LENGTH:  517\n",
            "EPISODE:  1000 \tREWARD:  -525.0 \tMEAN_REWARD:  -356.64 \tEPISODE_LENGTH:  525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR04Asc-CcHr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b661be8c268d4f2ca1b01cfe9d311f1e",
            "25b31b5230bc444aaabbff33695372b4",
            "28ae0cb36990470ea877e2e578585def",
            "f1281fd62a4c4b0590d80d95754494f0",
            "c677d66a87b446178a754e14fca068cb",
            "77ef7dcf0bd4404b851e6fe956f5f5a6",
            "10bfe22c409549798ec7e77c654a8779",
            "68789599a4ce41539b16a947b413a7a3",
            "6ded7492f9a4481ea2fe218e425ad151",
            "3d3f219fe33644a396e63cf7c0b5d7ef",
            "d28f8742420e419f8c6fa5549eae877a"
          ]
        },
        "outputId": "f9b4aa49-cbcb-448c-cb5e-b157b1c2de45"
      },
      "source": [
        "runner = Runner(\n",
        "    agent = RLAgent(agent_config=mountaincar_noise_config),\n",
        "    env_id = environments.MOUNTAINCAR_NOISE,\n",
        "    log_interval = LOG_INTERVAL\n",
        ")\n",
        "runner.play_episodes()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[37mLoaded bsuite_id: mountain_car_noise/1.\u001b[0m\n",
            "\u001b[1m\u001b[33mLogging results to CSV file for each bsuite_id in results.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b661be8c268d4f2ca1b01cfe9d311f1e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(9, 24) 1000\n",
            "(13, 28) 1000\n",
            "(20, 18) 1000\n",
            "(8, 15) 1000\n",
            "(11, 23) 1000\n",
            "(4, 19) 1000\n",
            "(22, 16) 1000\n",
            "(17, 18) 1000\n",
            "(14, 19) 1000\n",
            "(14, 14) 998\n",
            "(15, 13) 999\n",
            "(22, 16) 1000\n",
            "(22, 29) 1000\n",
            "(17, 18) 997\n",
            "(12, 23) 1000\n",
            "(11, 17) 998\n",
            "(11, 18) 999\n",
            "(15, 18) 1000\n",
            "(9, 28) 997\n",
            "(14, 20) 1000\n",
            "(21, 16) 1000\n",
            "(14, 18) 1000\n",
            "(24, 25) 999\n",
            "(9, 17) 997\n",
            "(12, 13) 996\n",
            "(16, 23) 998\n",
            "(14, 20) 995\n",
            "(21, 22) 1000\n",
            "(9, 27) 999\n",
            "(14, 14) 999\n",
            "(16, 7) 1000\n",
            "(12, 13) 996\n",
            "(12, 32) 996\n",
            "(9, 28) 996\n",
            "(21, 24) 995\n",
            "(22, 20) 995\n",
            "(21, 20) 998\n",
            "(15, 17) 996\n",
            "(13, 31) 997\n",
            "(7, 24) 999\n",
            "(11, 28) 991\n",
            "(1, 23) 996\n",
            "(12, 7) 999\n",
            "(7, 13) 995\n",
            "(4, 13) 996\n",
            "(11, 28) 997\n",
            "(12, 18) 994\n",
            "(13, 15) 996\n",
            "(22, 16) 994\n",
            "(11, 12) 999\n",
            "(25, 28) 992\n",
            "(23, 11) 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-6ff2d7cdd495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlog_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLOG_INTERVAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_episodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bsuite/aicrowd/runner.py\u001b[0m in \u001b[0;36mplay_episodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mnext_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_observation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bsuite/utils/gym_wrapper.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_GymTimestep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtimestep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_observation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bsuite/utils/wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mtimestep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_track\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bsuite/utils/wrappers.py\u001b[0m in \u001b[0;36m_track\u001b[0;34m(self, timestep)\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_len\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_return\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/dm_env/_environment.py\u001b[0m in \u001b[0;36mlast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mStepType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mStepType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLAST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M3w5s_7Zz85"
      },
      "source": [
        "# **Analysis & Result**\n",
        "\n",
        "The following cells will show the score of the agent on each environment. The same scoring method will be used to evaluate your agent on a set of test environments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbiYZYkkzp5s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "outputId": "a46cd593-105b-4d84-ca4e-ac8a8ca6b8c7"
      },
      "source": [
        "# *** PLEASE DONT EDIT THE CONTENTS OF THIS CELL ***\n",
        "analyzer = Analyzer(os.environ.get('RESULTS_DIR'))\n",
        "analyzer.print_scores()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'total_regret'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-ed60a2bdf4cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# *** PLEASE DONT EDIT THE CONTENTS OF THIS CELL ***\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RESULTS_DIR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bsuite/aicrowd/analysis.py\u001b[0m in \u001b[0;36mprint_scores\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"ENVIRONMENT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SCORE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bsuite/aicrowd/analysis.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mSCORE_CATCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCATCH_DF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mSCORE_CATCH_NOISE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_noise_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCATCH_NOISE_DF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mSCORE_CARTPOLE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcartpole_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCARTPOLE_DF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bsuite/experiments/catch/analysis.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;34m\"\"\"Output a single score for catch.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   return plotting.ave_regret_score(\n\u001b[0;32m---> 34\u001b[0;31m       df, baseline_regret=BASE_REGRET, episode=sweep.NUM_EPISODES)\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bsuite/utils/plotting.py\u001b[0m in \u001b[0;36mave_regret_score\u001b[0;34m(df, baseline_regret, episode, regret_column)\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;34m\"\"\"Score performance by average regret, normalized to [0,1] by baseline.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0mn_eps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0mmean_regret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_eps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregret_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_eps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0munclipped_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbaseline_regret\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_regret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbaseline_regret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munclipped_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3485\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3487\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'total_regret'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldLVxBn75Dgv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "outputId": "b51e5dd7-416f-4c8b-e1d8-99ad966ff9bc"
      },
      "source": [
        "# If you want a object to get the scores\n",
        "analyzer.get_scores()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'total_regret'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-b2d579300a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If you want a object to get the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bsuite/aicrowd/analysis.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mSCORE_CATCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCATCH_DF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mSCORE_CATCH_NOISE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_noise_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCATCH_NOISE_DF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mSCORE_CARTPOLE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcartpole_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCARTPOLE_DF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bsuite/experiments/catch/analysis.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;34m\"\"\"Output a single score for catch.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   return plotting.ave_regret_score(\n\u001b[0;32m---> 34\u001b[0;31m       df, baseline_regret=BASE_REGRET, episode=sweep.NUM_EPISODES)\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bsuite/utils/plotting.py\u001b[0m in \u001b[0;36mave_regret_score\u001b[0;34m(df, baseline_regret, episode, regret_column)\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;34m\"\"\"Score performance by average regret, normalized to [0,1] by baseline.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0mn_eps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0mmean_regret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_eps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregret_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_eps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0munclipped_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbaseline_regret\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_regret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbaseline_regret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munclipped_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3485\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3487\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'total_regret'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csfXypp1MAYv"
      },
      "source": [
        "## What is the score function\n",
        "\n",
        "The score function is developed by the BSuite team at Deepmind. It is open source and available at https://github.com/deepmind/bsuite\n",
        "\n",
        "The score measures behavioral aspects of the agent only, and does not take into account internal state of the agent. For more details read Section 2 of the [BSuite paper](https://openreview.net/forum?id=rygf-kSYwH). In this case we use only the \"Basic\" aspect of the agent's scoring system.\n",
        "\n",
        "**It is not necessary to understand the score in order to improve your agent's performance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvSY6g4p9Geu"
      },
      "source": [
        "# **Backend Evaluation**\n",
        "\n",
        "THIS CODE WILL EVALUATE THE AGENT USING THE SPECIFIED CONFIGS FOR THE CORRESPONDING ENVIRONMENTS. DO NOT EDIT THE CONTENTS OF THIS CELL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_81Xj8C9E9E"
      },
      "source": [
        "## Do not edit this cell\n",
        "if (os.environ.get('BACKEND_EVALUATOR') is not None):\n",
        "    \n",
        "    import backend_evaluator\n",
        "\n",
        "    runs = {\n",
        "        'catch': (\n",
        "            backend_evaluator.CATCH, \n",
        "            catch_config),\n",
        "        'catch_noise': (\n",
        "            backend_evaluator.CATCH_NOISE, \n",
        "            catch_noise_config),\n",
        "        'cartpole': (\n",
        "            backend_evaluator.CARTPOLE, \n",
        "            cartpole_config),\n",
        "        'cartpole_noise': (\n",
        "            backend_evaluator.CARTPOLE_NOISE, \n",
        "            cartpole_noise_config),\n",
        "        'mountaincar': (\n",
        "            backend_evaluator.MOUNTAINCAR, \n",
        "            mountaincar_config),\n",
        "        'mountaincar_noise': (\n",
        "            backend_evaluator.MOUNTAINCAR_NOISE, \n",
        "            mountaincar_noise_config)\n",
        "    }\n",
        "\n",
        "    for run_name, run in runs.items():\n",
        "        env_ids, config = run\n",
        "        for env_id in env_ids:\n",
        "            runner = Runner(env_id=env_id,\n",
        "                            agent=RLAgent(agent_config=config),\n",
        "                            verbose=False,\n",
        "                            eval=True)\n",
        "            runner.play_episodes()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbgvyHFX5I7u"
      },
      "source": [
        "# Submit to AIcrowd 🚀\n",
        "\n",
        "**NOTE: PLEASE SAVE THE NOTEBOOK BEFORE SUBMITTING IT (Ctrl + S)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwzRiuBy5I7u"
      },
      "source": [
        "! aicrowd notebook submit --no-verify -c iitm-rl-final-project -a assets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrE7MnNsr3eR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}